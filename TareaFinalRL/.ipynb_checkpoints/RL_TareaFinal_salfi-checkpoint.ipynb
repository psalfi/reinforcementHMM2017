{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugando Atari con Julia y Reinforcement Learning\n",
    "\n",
    "No nos emocionemos aun, todavia hay un largo camino por recorrer... Entrenar un programa (agente) que aprenda a jugar a nivel humano toma mucha paciencia y horas de entrenamiento; un solo paso equivocado y no lo vamos a lograr. \n",
    "\n",
    "Para aprender a resolver problemas complejos, lo primero que tenemos que hacer es comprender las complicaciones detras de cada parte de esta tarea. Para esto, necesitamos comenzar con problemas sencillos y escalarlos poco a poco. Necesitamos comenzar haciendo un pequeño viaje en el tiempo a la historia reciente de la Inteligencia Artificial y el Reinforcement Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MDPs\n",
    "\n",
    "Nuestra historia comienza con Richard Bellman (*A Markovian Decission Process* 1957) y Ronald Howard (*Dynamic Programming and Markov Processes* 1960), que extendio la teoria de Bellman.\n",
    "\n",
    " <center><table><tr>\n",
    "  <td><img src=\"Images/bellman.jpg\" alt=\"Richard Bellman\" width=\"150\">\n",
    "  <figcaption>Fig1.a - El es Bellman.</figcaption></td>\n",
    "  <td><img src=\"Images/howard.jpg\" alt=\"Ronald Markov\" width=\"150\">\n",
    "  <figcaption>Fig1.b - El es Howard.</figcaption></td>\n",
    "  <td><img src=\"Images/markov.jpg\" alt=\"Andrey Markov\" width=\"150\">\n",
    "  <figcaption>Fig1.c - El es Markov.</figcaption></td>\n",
    "</table></center>\n",
    "\n",
    "Bellman tuvo una idea muy simple de como modelar un proceso de aprendizaje. En cada momento del tiempo $t$, un agente debe tomar una decision (accion) $A_t$ dependiendo del estado del ambiente $S_t$; en el momento que el agente toma su decision, interactua con el ambiente y lo transforma, llevando al sistema a un nuevo estado $S_{t+1}$. ¿Como puede saber el agente si actuo correcta o incorrectamente? Para eso necesita una señal de reforzamiento o pago. Por esta razon, suponemos ademas que el agente recibe un pago $R_{t+1}$ en el momento que el sistema se transforma.\n",
    "\n",
    " <center>\n",
    " <img src=\"Images/mdp_process.png\" alt=\"MDP Representation\" width=\"400\" height=\"225\">\n",
    " <figcaption>Fig2. - Este es el ciclo de una tarea de aprendizaje.</figcaption>\n",
    "</center>\n",
    "\n",
    "¿Y que tiene que ver con Markov? Bellman es uno de los desarrolladores de la *Programacion Dinamica*, que es una tecnica para resolver problemas matematicos en los que las variables que queremos encontrar dependen del tiempo y la solucion en un momento $t$ se puede expresar en terminos de la solucion al tiempo $t-1$. La idea central del trabajo de Bellman consiste en que para encontrar las decisiones optimas $A_t, A_{t+1},...$ de forma que maximicen el total de pagos recibidos en el tiempo $R_{t+1}, R_{t+2}, ...$ tenemos que suponer que el estado futuro del sistema es independiente del pasado condicionado a su estado actual y de las decisiones del agente. Esta propiedad se conoce como la propiedad de Markov. En terminos matematicos, la implicacion de esta condicion es\n",
    "$$\n",
    "P(S_{t+1}, R_{t+1} \\mid S_0, A_0, R_0, ..., S_t, A_t, R_t) = P(S_{t+1}, R_{t+1} \\mid S_t, A_t).\n",
    "$$\n",
    "En otras palabras, las probabilidades de transicion $(S_t,A_t) \\to (S_{t+1}, R_{t+1})$ y las decisiones del agente determinan todo el comportamiento del sistema. Un problema reforzamiento con la propiedad de Markov se conoce como un *Markov Decission Process* o MDP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un juego de Atari como un MDP\n",
    "\n",
    "<center>\n",
    " <img src=\"Images/pong.jpg\" alt=\"Pong\" width=\"150\">\n",
    " <figcaption>Fig3. - El juego de de Atari Pong.</figcaption>\n",
    "</center>\n",
    "\n",
    "Este tutorial es acerca de como resolver juegos de Atari en Julia. Para promover el desarollo de algoritmos de Inteligencia Artificial y Reinforcement Learning, la organizacion OpenAI creo la interfaz [Open AI Gym](https://gym.openai.com/) que facilita el desarollo y evaluacion de algoritmos de aprendizaje. La mala noticia es que solo esta disponible para Python y es casi imposible de instalar en Windows. La buena noticia es que Julia tiene una interfaz para interactuar con Python de forma muy sencilla y no sera una limitacion.\n",
    "\n",
    "Por supuesto que pueden optar por implementar sus algoritmos directamente en Python y no en Julia. Pero este es un tutorial de Julia, que explota la belleza, facilidad y velocidad de Julia.\n",
    "\n",
    "Por favor vean la pagina de Open AI Gym directamente para instrucciones de como instalar la libreria `gym` de Python. Para poder usar `gym` en Julia, deberan antes tener la paqueteria de Interfaz con Python llamada `PyCall`. Para instalarla, usen el comando `Pkg.add(\"PyCall\")`.\n",
    "\n",
    "El siguiente codigo muestra como cargar el juego de Pong y hacer unas cuantas simulaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-02 18:48:01,919] Making new env: Pong-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <TimeLimit<AtariEnv<Pong-v0>>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall # use Pkg.add(\"PyCall\") to install\n",
    "@pyimport gym # most have gym installed on your computer's Python distribution\n",
    "pong = gym.make(\"Pong-v0\") # crea el ambiente de juego Pong en el objeto pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un MDP tiene estados y acciones disponibles, para saber cuales son con un objeto del tipo Pong, podemos usar las acciones de la paqueteria de Python gym.\n",
    "\n",
    "### Conjunto de Estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Box(210, 160, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong[:observation_space] # pong.observation_space en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es que el espacio de estados es una \"caja\" de dimensiones $210 \\times 160 \\times 3$. Aunque en los metodos de Reinforcement Learning no necesitaremos saber el significado de los estados,  en este caso sabemos de antemano que va el juego va a regresar los componentes RGB de los pixeles del juego. El juego tiene una resolucion de $210 \\times 160$ y por cada uno tiene tres componentes de color. Un componente de color es un valor en el rango $0--255$. Si no supieramos esto, pudiese haber usado las siguientes funciones para determinar la frontera del espacio de observaciones\n",
    "* `pong[:observation_space][:high]`\n",
    "* `pong[:observation_space][:low]`\n",
    "\n",
    "No las incluimos aqui porque el resultado es muy grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de Acciones\n",
    "\n",
    "Determinar el conjunto de acciones es muy similar, para eso podemos usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Discrete(6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong[:action_space] # pong.action_space en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso es discreto (el conjunto de acciones siempre es discreto en estas pruebas). Eso quiere decir que solo puede obtener los valores $0-5$. Si! Empieza en cero, es una de las herencias por la interfaz con Python.\n",
    "\n",
    "Otra manera de encontrar el numero de acciones es simplemente con el comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong[:action_space][:n] # pong.action_space en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el espacio de observacion y espacio de accion son objetos de Python que pertenecen a la clase \"espacios\" y tienen implementado un metodo muy util para tomas muestras aleatorias de estos espacios. Eso sera muy util al principio, para poder demostrar algunas simulaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong[:action_space][:sample]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afortunadamente para los metodos de Reinforcement Learning, tampoco necesitamos saber el significado de estas acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulando transiciones del MDP\n",
    "\n",
    "Ahora lo mas divertido, veamos primero como simular una transicion usando el metodo `step` de los ambientes de `gym`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_state = pong[:reset]() # comienza oficialmente el ambiente Pong poniendo en su estado inicial\n",
    "action = pong[:action_space][:sample]() # escoje una accion al azar, ojo no depende del estado inicial\n",
    "    # por ser completamente aleatorio, pero en principio deberia...\n",
    "new_state, reward, done, info = pong[:step](action)\n",
    "; # para que no imprima el resultado de la celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El metodo `step` recibe una accion (en realidad, tambien recibe el estado actual, para ya esta codificado dentro del ambiente) y regresa cuatro cosas\n",
    "* `new_state`: El nuevo estado del ambiente\n",
    "* `reward` El pago recibido por la accion decididad\n",
    "* `done` Una variable booleana que determina si el episodio esta terminado \n",
    "* `info` Un diccionario que trae informacion adicional del juego, en teoria nunca deberiamos necesitarla.\n",
    "\n",
    "La funcion `step` tiene implica las probabilidades de transicion $(S_t, A_t)\\to (S_{t+1}, R_{t+1})$ del MDP. No son explicitas porque no regresa toda la distribucion, simplemente un muestreo de esa distribucion. Esta es la dificultad a la que nos enfrentamos.\n",
    "\n",
    "### Simulando y visualizando todo un episodio \n",
    "\n",
    "Veamos ahora como podriamos simular y visualizar un episodio entero. Para visualizar el estado del ambiente necesitaremos el metodo `render`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio terminado con pago total: -"
     ]
    }
   ],
   "source": [
    "initial_state = pong[:reset]() \n",
    "done = false\n",
    "episode_reward = 0.\n",
    "while !done # cicla hasta que la funcion step marque el fin del episodio\n",
    "    pong[:render]() # crea la visualizacion del juego\n",
    "    action = pong[:action_space][:sample]() \n",
    "    state, reward, done, info = pong[:step](action)\n",
    "    episode_reward += reward\n",
    "end\n",
    "println(\"Episodio terminado con pago total: \", episode_reward)\n",
    "pong[:render](close = true) # cierra la visualizacion del juego "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Felicidades!!!** Con esta parte del tutorial, ya sabes todo lo que necesitabas de los ambientes de `gym`! \n",
    "\n",
    "Desafortunadamente, resolver el juego de Pong no es facil pues el espacio de estados viene en terminos de pixeles y eso significa muchas posibilidades (aun cuando no las veamos todas). De momento, trataremos de resolver un problema mas sencillo, primero deberan hacer el siguiente ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'> Ejercicio 1 </span>\n",
    "\n",
    "Antes de poder juegos de Atari, vamos a utilizar el ambiente \"MountainCar-v0\" que es una muy sencilla y clasica prueba de algoritmos de Inteligencia Artificial. El problema consiste en un coche que tiene que subir una colina pero su motor no tiene la fuerza necesaria. Para esto tiene que ir de lado en lado construyendo inercia.\n",
    "\n",
    "<center>\n",
    " <img src=\"Images/mountainCar.jpg\" alt=\"Mountain Car\" width=\"300\" height=\"225\">\n",
    " <figcaption>Fig3. - Problema del coche de la colina.</figcaption>\n",
    "</center>\n",
    " \n",
    "Introduce el codigo para cargar el ambiente \"MountainCar-v0\" y realiza la simulacion de 10 episodios tomando decisiones completamente aleatorias con la funcion `sample` del espacion del ambiente. Tu codigo debe imprimir \n",
    "1. El pago total acumulado por cada episodio\n",
    "2. El total de pasos por episodio\n",
    "3. El tiempo total por episodio, puedes usar las funciones tic() y toq() de julia para esto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-02 18:48:16,872] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <TimeLimit<MountainCarEnv<MountainCar-v0>>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall # use Pkg.add(\"PyCall\") to install\n",
    "@pyimport gym # most have gym installed on your computer's Python distribution\n",
    "hill = gym.make(\"MountainCar-v0\") # crea el ambiente de juego Pong en el objeto pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.272683264 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 1.272683264\n",
      "elapsed time: 1.36839384 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 2.641077104\n",
      "elapsed time: 1.521965865 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 4.163042969\n",
      "elapsed time: 1.315390787 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 5.478433756\n",
      "elapsed time: 1.310079793 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 6.788513549\n",
      "elapsed time: 1.354991585 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 8.143505134\n",
      "elapsed time: 1.448002715 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 9.591507849\n",
      "elapsed time: 1.336035362 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 10.927543211\n",
      "elapsed time: 1.332396871 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 12.259940082\n",
      "elapsed time: 1.326206141 seconds\n",
      "Episodio terminado con pago total: -200.0\n",
      "El total de pasos por episodio: 200.0\n",
      "El tiempo total por episodio: 13.586146223\n"
     ]
    }
   ],
   "source": [
    "initial_state = hill[:reset]() \n",
    "done = false\n",
    "episode_reward = 0.\n",
    "step = 0.\n",
    "time = 0.\n",
    "\n",
    "for i = 0:9\n",
    "    initial_state = hill[:reset]() \n",
    "    done = false\n",
    "    episode_reward = 0.\n",
    "    step = 0.\n",
    "    #time = 0.\n",
    "    tic()\n",
    "  while !done # cicla hasta que la funcion step marque el fin del episodio\n",
    "    #timeIni=tic()\n",
    "    hill[:render]() # crea la visualizacion del juego\n",
    "    action = hill[:action_space][:sample]() \n",
    "    state, reward, done, info = hill[:step](action)\n",
    "    episode_reward += reward\n",
    "    step = step + 1\n",
    "end\n",
    "time += toc()\n",
    "    \n",
    "println(\"Episodio terminado con pago total: \", episode_reward)\n",
    "println(\"El total de pasos por episodio: \", step)\n",
    "println(\"El tiempo total por episodio: \", time)\n",
    "hill[:render](close = true) # cierra la visualizacion del juego \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Control optimo\n",
    "\n",
    "La regla de toma de decision del agente se conoce como *politica*. La regla no tiene porque ser deterministica, y de hecho, matematicamente conviente pensar esta regla como una distribucion de probabilidad sobre todas las posibles acciones. Para ser mas preciso, una politica es una forma de convertir el estado actual $S_t$ en un accion $A_t$, es decir, es una familia de distribuciones condicionales $\\pi(A_t \\mid S_t) := P(A_t \\mid S_t)$.\n",
    "\n",
    "El problema del control optimo es el de encontrar una politica $\\pi^*$ para un MDP que maximice la ganancia total \n",
    "$$\n",
    "\\pi^* = \\mathrm{argmax}_\\pi E \\left[ R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} \\cdots  \\gamma^{T-1} R_T\\right].\n",
    "$$\n",
    "En esta formula, necesitamos una esperanza porque la suma total de ganancias es aleatoria. El simbolo $\\gamma$ es una constante $0<\\gamma\\leq 1$ que representa la preferencia intertemporal. Cuando $\\gamma < 1$, se valora mas un retorno en el presente que en el futuro; nosotros supondremos $\\gamma = 1$ por simplicidad.\n",
    "\n",
    "Teoricamente, el trabajo de Bellman y Howard de Programacion Dinamica para MDPs mostro que siempre es posible encontrar la politica optima si se conoce completamente las probabilidades de transicion $P(S_{t+1}, R_{t+1}| S_t, A_t)$ del MDP. En la practica, enfrentamos un problema adicional: normalmente el agente intentando aprender no conoce las probabilidades de transicion del MDP y por lo tanto no puede recurrir a los metodos exactos de la programacion dinamica para encontrar una politica optima; mas aun, aun cuando si pueda conocer estas probabilidades, en ocasiones la cantidad de estados del sistema es tan grande que los metodos analiticos de la programacion dinamica no son suficiente (por ejemplo, se estima que una partida de ajedrez puede tener hasta $10^{45}$ configuraciones distintas, totalmente intratable para los metodos exactos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las Ecuaciones de Bellman\n",
    "\n",
    "Aunque los metodos de Programacion Dinamica son frecuentemente impracticos para buscar politicas optimas, son la piedra angular para entender las estrategias exitosas de solucion. Si un sistema se encuentra en un estado $S_t$, el valor esperado que recibira el agente al tomar la decision $A_t$ es\n",
    "$$\n",
    "Q_\\pi(S_t,A_t) := E_\\pi\\left[ R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} \\cdots  \\gamma^{T-1} R_T \\mid S_t, A_t \\right]\n",
    "$$\n",
    "Las ecuaciones de Bellman son ecuaciones recursivas en terminos de la *la funcion de valor estado-accion $Q$*. La propiedad de Markov garantiza que en cualquier momento del tiempo, el futuro del sistema depende solo de su estado actual y de la decision del agente. Como consecuencia de esta \"perdida de memoria\", despues de una transicion $(S_t, A_t) \\to (S_{t+1}, R_{t+1})$ y una proxima accion $A_{t+1}$ del agente, el sistema vuelve a empezar, por lo que se tiene la identidad\n",
    "$$\n",
    "Q_\\pi(S_t,A_t) = E_\\pi\\left[R_{t+1} + \\gamma Q_\\pi(S_{t+1}, A_{t+1})]\\right] \\quad\\quad \\text{(Ecuacion de Bellman 1)}\n",
    "$$\n",
    "La ecuacion anterior debe una historia:\n",
    "\n",
    "<blockquote> El agente (con politica) $\\pi$ se encuentra en el estado $S_t$ y decide la accion $A_t$. Justo en este momento tiene una promesa de pago futuro de $Q_\\pi(S_t, A_t)$. Tras decidir, el sistema transiciona al estado $S_{t+1}$ recibiendo un pago recibe un pago de $R_{t+1}$ por su decision. Ahora tendra que decidir nuevamente una accion $A_{t+1}$ y tendra una promesa de pago futuro de $Q_\\pi(S_{t+1}, A_{t+1})$. El pago $R_{t+1}$ que recibio mas la esperanza de pago futuro $Q_\\pi(S_{t+1}, A_{t+1})$ deben de ser igual a la promesa de pago $Q_\\pi(S_t, A_t)$ que tenia entes de la transicion.\n",
    "</blockquote>\n",
    "\n",
    "Esta ecuacion es la primera de las ecuaciones de Bellman y se cumple para todas las politicas $\\pi$. La utilidad de esta ecuacion es evaluar la politica actual $\\pi$. \n",
    "\n",
    "Aunque existen formar de mejorar la politica $\\pi$ una vez que se conoce $Q_\\pi$, Bellman tambien encontro una ecuacion recursiva que se cumple unicamente por la politica optima $\\pi^*$ y que puede ser usada para encontrar la politica optima directamente. La segunda ecuacion o *ecuacion de optimalidad de Bellman* dice\n",
    "\n",
    "$$\n",
    "Q_{\\pi^*}(S_t,A_t) = E_{\\pi^*}\\left[ R_{t+1} + \\gamma \\max_A Q_{\\pi^*}(S_{t+1}, A)]\\right] \\quad\\quad \\text{(Ecuacion de Bellman 2)}.\n",
    "$$\n",
    "\n",
    "El mecanismo detras de esta expresion recursiva descubierta por Bellman se basa en que un individuo racional siempre escoge la accion que maximiza su utilidad esperada, que en terminos de la funcion $Q_{\\pi^*}$ implica\n",
    "$$\n",
    "\\pi^*(S_t) = \\mathrm{argmax}_A Q_{\\pi^*}(S_t,A).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "El *Reinforcement Learning* (RL) busca resolver las limitaciones que de la programacion Dinamica tradicional para resolver MDPs. En RL tener un modelo del ambiente (probabilidades de transicion) es optativo y sirve para hacer planeacion y mejorar los algoritmos, pero no es necesario. Las estrategias de Reinforcement Learning evaluan una politica y la mejoran siguiendo estrategias iterativas. \n",
    "\n",
    "Podriamos agrupar a los diversos metodos del RL en tres grupos dependiendo de su grado de \"supervision\":\n",
    "\n",
    "1. **Metodos de Programacion Dinamica**: Utilizan de forma directa las ecuaciones de Bellman y necesitan de un conocimiento de las probabilidades de transicion $P(S_{t+1},A_{t+1}\\mid S_t, A_t)$, de lo contrario, pueden intentar estimarlas estadisticamente a traves de simulacion. Aunque son muy precisos, son altamente demandantes en terminos de memoria y poder computacional, y requieren de un conocimiento de las probabilidades de transicion del ambiente que rara vez se tienen completamente disponibles.\n",
    "2. **Metodos de Funciones de Valor**: En vez de intentar conocer las probabilidades de transicion, estos metodos buscan estimar la funcion de valor $Q$ de la politica optima usando la ley de los grandes numeros (LGN). Una vez estimada la funcion Q optima, podemos recuperar la politica optima poniendo $\\pi^*(S_t) = \\mathrm{argmax}_A Q_{\\pi^*}(S_t,A)$. Mas adelante veremos en que formas las Ecuaciones de Bellman y la LGN permiten conocer $Q$.\n",
    "3. **Metodos de Gradientes de Politica**: Este ultimo grupo es el menos supervisado y trata directamente  de encontrar unas distribuciones de probabilidad $\\pi(A \\ S)$ para cada pareja estado-accion $(S,A)$, sin pasar por la funcion $Q$, y tratando de maximizar la utilidad acumulada $R_{t+1} + \\gamma R_{t+2} + \\cdots + \\gamma^{T-1}$. Es es el metodo buscar patrones en los estados $S_t$ que directamente se correlacionen con mayores pagos.\n",
    "\n",
    "Ambos enfoque 2 y 3 son muy populares actualmente. La ventaja de los ultimos es que tienen menos supuestos al ser menos estructrados. Su desventaja es que tambien son mayores cajas negras y en la practica pueden ser tan o mas dificiles de implementar. Aun no queda claro cual es el mejor enfoque, si es que hay alguno, pueden leer una comparacion en [este link](http://www.mcgovern-fagg.org/amy/pubs/tr-06-001.pdf).\n",
    "\n",
    "**Nosotros vamos a utilizar el el enfoque de funciones de valor**, pues da un equilibrio entre estructura y practicidad.\n",
    "\n",
    "## Politcas optimas y $\\epsilon$-greegy \n",
    "\n",
    "En la realidad, nuestros algoritmos no escogeran siempre la decision optima $\\pi^*(S_t)$, pero si con una probabilidad $(1-\\epsilon)$ donde $\\epsilon$ ira decreciendo con el tiempo. El problema de escoger siempre la decision optima es que en la practica no sabemos a la perfeccion los parametros del MDP, y un agente que no explore, tiene el riesgo de llegar a conclusiones equivocadas prematuramente y nunca encontrar la politica optima. Este tipo de politicas se conocen como $\\epsilon$-greedy.\n",
    "\n",
    "## Implementacion en Julia de la funcion de valor Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">**Advertencia!**  **Hasta nuevo aviso, supondremos que el conjunto de estados es discreto, pues aun no estamos en facultad de desarollar teoria para conjuntos de estados continuos.**.</span>\n",
    "\n",
    "La forma mas tentadora de almacenar la informacion de $Q$ es utilizando una matriz o un vector. Pero usualmente es mucho mas conveniente usar *tablas hash*, que en Julia (y Python) son llamadas *diccionarios*. Una tabla hash es una estructura de datos que consiste de *claves* y *valores*, asignando a cada clave un valor. Es una estructura no ordenada, a diferencia de un vector. Estas son algunas ventajas\n",
    "\n",
    "* Usualmente iniciamos los diccionarios vacios y agregamos claves la primera vez que ocurren. En problemas de reinforcement learning hay muchisimos estados que nunca son visitados y que resulta ineficiente o imposible almacenar un valor para cada estado (como en el ajedrez). Las tablas has permite solo asignar valores a las tuplas (estado, accion) observadas, mas similar a como aprendemos en la realidad.\n",
    "* Con un diccionario los estados pueden ser claves aunque en si mismos sean arrays o objetos compuestos. Muchas otras estructuras necesitan de \"nombres\" en los estados, y por lo tanto solo pueden ser strings.\n",
    "\n",
    "Para inicializar un diccionaro vacio en Julia usamos la funcion `Dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 0 entries"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = Dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las parejas estado-accion se pueden modelar como tuplas, representadas en Julia con parentesis $(s,a)$. El siguiente ejemplo muestra como manipular $Q$ como un diccionario que tiene como claves las tuplas $(s,a)$. Se pueden usar brackets [ ] para acceder el valor de las claves del diccionario y para signar nuevos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estado = \"Some state\"\n",
    "accion = \"Some action\"\n",
    "Q[(estado, accion)] = 1.\n",
    "Q[(estado, accion)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acceder a las claves actualmente guardadas se puede usar el comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.KeyIterator for a Dict{Any,Any} with 1 entry. Keys:\n",
       "  (\"Some state\",\"Some action\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos consultar si el diccionario tiene una clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haskey(Q, (estado, accion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una funcion implementada comunmente es las tablas Hash es el metodo `get` que busca una clave y si no la encuentra regresa un valor *default*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_value = 0.\n",
    "get(Q, \"I am not a key\", default_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacion en Julia de una politica $\\epsilon$-greedy en Julia\n",
    "\n",
    "La implementacion de la politica de un agente puede ser implica o explicita\n",
    "* Es *explicita* si dado un estado devuelve la distribucion de probabilidad de la politica\n",
    "* Es *implicita* si dado un estado devuelve una observacion de la distribucion de la politica\n",
    "Aunque matematicamente modelamos una politica como una distribucion de probabilidad para cada estado. En la practica es muchas veces conveniente modelarla implicitamente. Una de las ventajas de los metodos de funciones de valor es que funcionan muy bien con politicas implicitas, que no necesitan almacenar una gran cantidad de valores por cada combinacion de estado accion, si no que reciben directamente a la funcion de valor $Q$ como argumento una accion.\n",
    "\n",
    "La politica debe consistir en los siguientes ingredientes:\n",
    "\n",
    "> ### Ingredientes de una politica de tipo $\\epsilon$-greedy:\n",
    "> * **Inputs**\n",
    ">    1. `state`: el estado actual en el cual se tiene que tomar una accion\n",
    ">    2. `actions`: las acciones disponibles al estado `state`\n",
    ">    3. `Q`: la mejor estimacion hasta el momento de la matriz `Q`, que se usara para tomar la decision greedy $$\\mathrm{greedy}(\\text{state}) = \\mathrm{argmax}_{a\\in\\text{actions}} Q(\\text{state}, a)$$\n",
    ">    4. $\\epsilon$: la probabilidad de tomar una decision completamente al azar y no greedy\n",
    "> * **Output**\n",
    ">    + La accion $\\mathrm{policy}(\\text{state})$ decidida por \n",
    ">        - aleatoriamente entre cualquier accion con probabilidad $\\epsilon$ \n",
    ">        - aleatoriamente entre las acciones que maximicen $Q(\\text{state}, \\cdot)$ con probabilidad $1-\\epsilon$.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Returns an action according to an ϵ-greedy policy given an estimate of the action value function Q.\n",
    "\"\"\"\n",
    "function policy(state::Any, action_space::Any, Q::Dict, ϵ::Float64)\n",
    "    random_number = rand()\n",
    "    if random_number < ϵ\n",
    "        return rand(action_space) #  totalmente aletorio\n",
    "    else\n",
    "        max_Q = maximum([get(Q, (state, a), 0.) for a in action_space]) # max_a Q(state, a)\n",
    "        greedy_actions = [a for a in action_space if get(Q, (state, a), 0.) == max_Q] # argmax_a Q(state, a)\n",
    "        return rand(greedy_actions) # aleatorio entre las mejores acciones solamente\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJEMPLO DE USO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 3 3 2 0 3 0 0 0 3 0 3 3 3 0 3 3 2 3 0 3 0 3 0 2 0 3 3 0 "
     ]
    }
   ],
   "source": [
    "Q = Dict()\n",
    "ϵ = 0.25 # 25% de aleatoriedad total\n",
    "state = \"Some state\"\n",
    "action_space = 0:3\n",
    "Q[(state, 0)] = Q[(state, 3)] = 1. # Las mejores acciones son 0 y 3\n",
    "Q[(state, 1)] = Q[(state, 2)] = 0. # Las peores acciones son 1 y 2\n",
    "for i in 1:30 # Imprime 30 simulaciones de acciones\n",
    "    print(policy(state, action_space, Q, 0.1), \" \")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'> Ejercicio 2 </span>\n",
    "\n",
    "1. Para el juego de MountainCar describe en una o dos oraciones lo que consideres es una politica optima\n",
    "2. Para el juego de Pong describe en una o dos oraciones que consideres es una politica optima\n",
    "3. Describe  en una o dos oraciones los potenciales peligros de tener una politica $\\epsilon$-greedy en la que $\\epsilon$ sea demasiado baja.\n",
    "4. Resume en una o dos oraciones las diferencias entre las dos ecuaciones de Bellman.\n",
    "5. Porque decimos que las ecuaciones de Bellman son recursivas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'> Respuestas ejercicio 2 </span>\n",
    "\n",
    "1. Para el juego de MountainCar describe en una o dos oraciones lo que consideres es una politica optima, \n",
    "\n",
    "    R. Sabemos que el Reward es -1 para cada paso en el tiempo, hasta alcanzar la posición objetivo de 0,5\n",
    "    y el conjunto de acciones y el espacio de acciones es A={[0,push left],[1,no push],[2, push right]}. La política óptima que se puede plantear sería por ejemplo que se incrementara el reward cuando el carro alcance la parte superior de la montaña, al tomar la acción de empujar hacia adelante,considerando los menos pasos posibles.\n",
    "\n",
    "\n",
    "2. Para el juego de Pong describe en una o dos oraciones que consideres es una politica optima\n",
    "\n",
    "R.  Sabemos que el espacio de estados es una caja de dimensiones 210x160x3; el conjuno de acciones en este caso es discreto, solo puede obtener los valores 0−5.  Una política óptima podría ser aquella que en que la distancia entre pixeles sea pequeña.\n",
    "\n",
    "\n",
    "3. Describe en una o dos oraciones los potenciales peligros de tener una política ϵϵ-greedy en la que ϵϵ sea demasiado baja.\n",
    "\n",
    "R. Que un agente no explore y que no se pueda obtener una política óptima. Mientras más pequeña sea ϵϵ puede que no se explore todo el espacio. \n",
    "\n",
    "4. Resume en una o dos oraciones las diferencias entre las dos ecuaciones de Bellman.\n",
    "\n",
    "R. La primera ecuación se cumple para todas las políticas, mientras que la segunda solo se cumple para aquella \n",
    "que es una política óptima.\n",
    "\n",
    "5. ¿Por qué decimos que las ecuaciones de Bellman son recursivas?\n",
    "\n",
    "Debido a que las variables que queremos encontrar dependen del tiempo y la solucion en un momento $t$ se puede \n",
    "expresar en términos de la solución al tiempo $t-1$. La idea central del trabajo de Bellman consiste en que para \n",
    "encontrar las decisiones óptimas $A_t, A_{t+1},...$ de forma que maximicen el total de pagos recibidos en el tiempo \n",
    "$R_{t+1},R_{t+2}, ...$ tenemos que suponer que el estado futuro del sistema es independiente del pasado (pérdida de \n",
    "memoria) condicionado a su estado actual y de las decisiones del agente. Esta propiedad se conoce como la propiedad \n",
    "de Markov.\n",
    "\n",
    "En otras palabras, las ecuaciones de Bellman son recursivas en términos de la función de valor estado accion $Q$. La propiedad de Marcov garantiza que en cualquier momento del tiempo el futuro del sistema depende de su estado actual y de la decisión del agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metodos tabulares de control optimo: Q-Learning y Sarsa\n",
    "\n",
    "Como mencionamos antes, los metodos de control optimo de Reinforcement Learning que vamos a usar se basan en la estimacion de la funcion de valor $Q$ y para eso usan las Ecuaciones de Bellman y la Ley de los Grandes Numeros (LGN). Vamos a tratar de clarificar un poco mas la razon.\n",
    "\n",
    "***Ley de los Grandes Numeros:* ** si se tiene una muestra de variables aleatorias independientes e identicas $X_1,...,X_n$ (con esperenza finita) entonces \n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^nX_i \\stackrel{n\\to\\infty}{\\to} E[X_i].\n",
    "$$\n",
    "\n",
    "Las exposiciones formales de los metodos de RL por funciones de valor y sus propiedades de convergencia puede ser muy extensa, pero la intuicion es increiblemente simple. Por ejemplo, para utilizar la LGN junto con la primera ecuacion de Bellman podemos hacer lo siguiente:\n",
    "\n",
    "<blockquote>\n",
    "<h3> Derivacion intuitiva de SARSA </h3>\n",
    "<oi>\n",
    "<li> Denotemos $Q_t$ la estimacion de $Q$ disponible al tiempo $t$. \n",
    "<li> Como \n",
    "$$E \\left[ R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) \\right] - Q(S_t, A_t) = 0$$\n",
    "segun la primera ecuacion de Bellman, entonces las diferencia \n",
    "$$\n",
    "\\delta_t(S_t, A_t) = R_{t+1} + \\gamma Q_t(S_{t+1}, A_{t+1})  - Q_t(S_t, A_t)\n",
    "$$\n",
    "nos da informacion de que tan bien o que tan mal esta la estimacion actual $Q_t(S_t, A_t)$.\n",
    "<li>  Como las cantidades $\\delta_t(S_t, A_t)$ son \"en promedio\" cero segun la LGN, entonces podemos dar pequeños pasas en la direccion $\\delta_t(S_t, A_t)$ para mejorar nuestra estimacion. Conforme los estados $(S_t, A_t)$ sigan aparenciendo en el futuro, tendremos una buena estimacion de $Q(S_t, A_t)$. Matematicamente\n",
    "$$\n",
    "Q_t(S_t, A_t) + \\alpha \\delta_t \\stackrel{t\\to \\infty}{ \\to} Q(S_t, A_t).\n",
    "$$\n",
    "<li> La constante $0 < \\alpha < 1$ se conoce como **velocidad de aprendizaje**. Valores tipicos son $\\alpha \\approx 0.025, 0.05, 0.1$ pero puede variar mucho de aplicacion en aplicacion.\n",
    "<li>  Una interpretacion intuitiva de $\\alpha$ es que define una nueva estimacion $Q_{t+1}(S_t, A_t)$, dandole un peso $(1-\\alpha)$ a la estimacion actual $Q_t(S_t, A_t)$ y un peso $\\alpha$ a la estimacion $R_{t+1} + \\gamma Q_t(S_{t+1}, A_{t+1}) $.\n",
    "</oi>\n",
    "</blockquote>\n",
    "\n",
    "La idea anterior se convierte en un metodo de control para encontrar una politica \"optima\" (ver el ejercicio debajo) llamado SARSA. El nombre SARSA se deriva de la regla de actualizacion de $Q$ que utiliza las variables $S_t, A_t, R_{t+1}, S_{t+1}, A_{t+1}$. La convergencia de este metodo (y tambien los casos en los que podria fallar) esta explicada por las teoria de *Aproximacion Estocastica*.\n",
    "\n",
    "\n",
    "> ### SARSA \n",
    ">\n",
    "> **Inputs**: \n",
    "  * Velocidad de aprendizaje $0 < \\alpha < 1$\n",
    "  * Tasa de descuento de la utilidad en el futuro $0 < \\gamma \\leq 1$ \n",
    "  * Una politica, tipicamente $\\epsilon$-greedy.\n",
    ">  \n",
    "> **Outputs**\n",
    "> * Una estimacion de la funcion de valor $Q$ bajo la politica $\\epsilon$-greedy\n",
    ">\n",
    "> **Algoritmo**\n",
    "> * **Inicializar** $Q$.\n",
    "> * **Para cada episodio** con estado-accion inicial $(s_0, a_0)$:\n",
    ">    + Para cada $t$ mientras el episodio no haya terminado:\n",
    ">        - **Hacer una transicion** a un nuevo estado-accion $(s_{t+1}, a_{t+1})$ obteniendo un pago $r_{t+1}$.\n",
    ">        - <span style='color: blue'>**Calcular la diferencia en utilidad segun la regla SARSA**</span>\n",
    ">          $$ \\delta_t = r_{t+1} + \\gamma Q(s_{t+1}, a_{t+1}) - Q(s_t,a_t) $$\n",
    ">        - **Actualizar el valor de $Q$**:\n",
    ">            $$ Q(s,a) = Q(s,a) + \\alpha\\delta_t$$  \n",
    " \n",
    "Cada vez que el algoritmo encuentre una pareja $(s,a)$ le debe asignar un valor por *default* a $Q(s,a)$. Lo tradicional es asignarle el valor $0$. Las propiedades de convergencia estocastico hacen que no importe este valor inicial.\n",
    "\n",
    "SARSA es un metodo **tabular** porque Q se calcular para cada posible tupla estado-accion. En la proxima tarea veran metodos aproximados que reducen el espacio de estados a un numero selecto de *features*.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'> Ejercicio 3 </span>\n",
    "\n",
    "1. Con SARSA se obtiene un estimacion de la funcion de valor $Q$ de la politica optima? Si no se obtiene la politica optima, que politica se obtiene? Es necesariamente malo una politica suboptima durante el proceso de aprendizaje?\n",
    "2. **(Q-LEARNING)** El famoso algoritmo Q-Learning (Watkins 1989) es identico al de SARSA salvo en una linea, reemplazamos la regla SARSA para $\\delta_t$ por\n",
    "$$ \\delta_t = r_{t+1} + \\gamma \\max_a Q_{\\pi^*}(s_{t+1}, a) - Q(s_t,a_t) $$\n",
    "Imitando la derivacion intuitiva de SARSA, explica intuitivamente el algoritmo Q-Learning usando la ecuacion de optimalidad de Bellman.\n",
    "3. SARSA se clasifica como un metodo de control *on-policy* y Q-Learning como *off-policy*. La razon es que no estiman la misma Q: uno de los metodos estima la optima y el otro no, incluso si ambos se implementan usando la misma politica $\\epsilon$-greedy. Investiga en maximo un parrafo mas sobre la diferencia entre SARSA y Q-Learning (o entre control *on-policy* y *off-policy*) y contesta: Es mejor un metodo off-policy que un metodo on-policy?\n",
    "4. Hay diferencia entre SARSA y Q-Learning conforme $\\epsilon \\to 0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: red'>Respuestas Ejercicio 3 </span>\n",
    "\n",
    "1. Con SARSA se obtiene un estimacion de la funcion de valor $Q$ de la politica optima? Si no se obtiene la politica optima, que politica se obtiene? Es necesariamente malo una politica suboptima durante el proceso de aprendizaje?\n",
    "\n",
    "R. No, SARSA compara el estado actual vs el estato actual siguiente.Se optine la mejor política dado epsilon. No es malo, pero usarla depende del problema del que estemos hablando.\n",
    "\n",
    "\n",
    "\t\n",
    "2. **(Q-LEARNING)** El famoso algoritmo Q-Learning (Watkins 1989) es identico al de SARSA salvo en una linea, reemplazamos la regla SARSA para $\\delta_t$ por\n",
    "$$ \\delta_t = r_{t+1} + \\gamma \\max_a Q_{\\pi^*}(s_{t+1}, a) - Q(s_t,a_t) $$\n",
    "Imitando la derivacion intuitiva de SARSA, explica intuitivamente el algoritmo Q-Learning usando la ecuacion de optimalidad de Bellman.\n",
    "\n",
    "<blockquote>\n",
    "<h3> Derivacion intuitiva de Q-Learning </h3>\n",
    "<oi>\n",
    "<li> Denotemos $Q_t$ la estimacion de $Q$ disponible al tiempo $t$. \n",
    "<li> Como \n",
    "$$E \\left[ R_{t+1} + \\gamma \\max_a Q_{\\pi^*}(S_{t+1}, A)) \\right] - Q(S_t, A_t) = 0$$\n",
    "segun la segunda ecuacion de Bellman, entonces las diferencia \n",
    "$$\n",
    "\\delta_t(S_t, A_t) = R_{t+1} + \\gamma max(Q_t(S_{t+1}, A))  - Q_t(S_t, A_t)\n",
    "$$\n",
    "nos da informacion de que tan bien o que tan mal esta la estimacion actual $Q_t(S_t, A_t)$ de $Q_*$\n",
    "<li>  Como las cantidades $\\delta_t(S_t, A_t)$ son \"en promedio\" cero segun la LGN, entonces podemos dar pequeños pasas en la direccion $\\delta_t(S_t, A_t)$ para mejorar nuestra estimacion. Conforme los estados $(S_t, A_t)$ sigan aparenciendo en el futuro, tendremos una buena estimacion de $Q(S_t, A_t)$. Matematicamente\n",
    "$$\n",
    "Q_t(S_t, A_t) + \\alpha \\delta_t \\stackrel{t\\to \\infty}{ \\to} Q_*(S_t, A_t).\n",
    "$$\n",
    "\n",
    "</oi>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "3. SARSA se clasifica como un metodo de control on-policy y Q-Learning como off-policy. La razon es que no estiman la misma Q: uno de los metodos estima la optima y el otro no, incluso si ambos se implementan usando la misma politica ϵϵ-greedy. Investiga en maximo un parrafo mas sobre la diferencia entre SARSA y Q-Learning (o entre control on-policy y off-policy) y contesta: Es mejor un metodo off-policy que un metodo on-policy?\n",
    "\n",
    "\n",
    "La mayor diferencia entre SARSA y Q-Learning, es que la máxima recompensa para el siguiente estado, no necesariemente es usadao para actualizar el valor de Q. En vez de ello, una nueva acción y su recompensa, es seleccinada usando la misma política que fue determinada en la acción original.\n",
    "\n",
    "Recall that the distinguishing\n",
    "feature of on-policy methods is that they estimate the value of a policy while using\n",
    "it for control. In o\u000b",
    "-policy methods these two functions are separated. The policy\n",
    "used to generate behavior, called the behavior policy, may in fact be unrelated to\n",
    "the policy that is evaluated and improved, called the target policy. An advantage of\n",
    "this separation is that the target policy may be deterministic (e.g., greedy), while\n",
    "the behavior policy can continue to sample all possible actions.\n",
    "Off-policy Monte Carlo control methods use one of the techniques presented in the\n",
    "preceding two sections. They follow the behavior policy while learning about and\n",
    "improving the target policy. These techniques requires that the behavior policy has\n",
    "a nonzero probability of selecting all actions that might be selected by the target\n",
    "policy (coverage).\n",
    "\n",
    "4. Hay diferencia entre SARSA y Q-Learning conforme $\\epsilon \\to 0$?\n",
    "\n",
    "Si, si epsilon gradualmente tiende a cero. Ambos métodos asintóticamente tiende a la política óptima\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's play\n",
    "\n",
    "Vamos a implementar el algoritmo SARSA para resolver el problema del coche en la colina. Cual es el primer problema que enfrentaremos? Preprocesar los estados.\n",
    "\n",
    "### Preprocesamiento de estados\n",
    "\n",
    "Este es el paso que en practicamente ninguna aplicacion de RL podemos escapar. Ademas, los distintos retos dependen del tipo de problema. Algunos puntos comunes que puede surgir son\n",
    "* **El espacio de estados es demasiado grande?**. Un ejemplo tipico es querer aprender juegos de Atari a traves de observar pixeles, pues muchos pixeles pueden hacer el conjunto de estados inmanejable. En la proxima tarea veremos metodos aproximados que ayudan a resolver el problema de un conjunto de estados muy grande creando features. En metodos tabulares hay que reducir el tamano del conjunto de estados, por ejemplo, en el caso de imagenes de Atari, comprimiendo el tamano de las imagenes y solo guardando la informacion mas importante de los pixeles.\n",
    "* **El espacio de estados es continuo?**. Si vamos a usar un metodo tabular como SARSA o Q-Learning sera necesario discretizar en un numero finito de valores. Debajo hacemos una demostracion. Nuevamente, los metodos aproximados pueden evitar la necesidad de discretizar.\n",
    "* **El espacio de estados es markoviano?**. Checar esta condicion es vital y usualmente ignorada. El funcionamiento correcto de los metodos depende del supuesto de Markov, i.e., que el futuro rendimiento dependa unicamente del estado actual y de la decision tomada. De manera practica podemos preguntar: conocer el ultimo estado es suficiente para tomar una decision optima?\n",
    "\n",
    "La siguiente funcion hace una discretizacion simple de un conjunto de estados de dimension $k$, seleccionando el valor minomo, maximo y el numero de puntos en cada dimension, asumiendo una discretizacion uniforme. Se pueden hacer funciones de discretizacion mucho mas sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each index `k` of the array `state`, it creates an even grid of length npoints[`k`] \n",
    "going from `lower[k]` to `upper[k]`, and returns the closest value of `state[k]` on that grid. \n",
    "All the arguments must be of the same length.\n",
    "\"\"\"\n",
    "function discretize(state::Array, lower::Array, upper::Array, npoints::Array) \n",
    "    discretized = Array{Float32}(length(state)) # preallocating is faster (but not necessary)\n",
    "    for k in 1:length(state)\n",
    "        grid = linspace(lower[k], upper[k], npoints[k]) # even space\n",
    "        discretized[k] = grid[indmin(abs(grid - state[k]))] # closest point\n",
    "    end\n",
    "    return discretized\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJEMPLO DE USO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-02 18:48:33,456] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569273,0.0] becomes Float32[-0.6,-0.01]\n"
     ]
    }
   ],
   "source": [
    "function preprocess(state::Array)\n",
    "    lower = [-1.2, -0.07]\n",
    "    upper = [0.6, 0.07]\n",
    "    npoints = [16, 8]\n",
    "    discretize(state, lower, upper, npoints)\n",
    "end\n",
    "\n",
    "mountain_car = gym.make(\"MountainCar-v0\")\n",
    "state = mountain_car[:reset]()\n",
    "println(state, \" becomes \", preprocess(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de entrenamiento\n",
    "\n",
    "Necesitamos una funcion que reciba una estimacion actual de la tabla $Q$ y que devuelva una estimacion mejorada. Notemos que la funcion depende del preprocesamiento que definimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APRENDIENDO UN EPISODIO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following function plays a gym_episode and learns using SARSA. It receives a current estimate of Q and \n",
    "returns an improved estimate Q, the episode reward and the number of steps.\n",
    "\"\"\"\n",
    "function learn_episode_with_sarsa(\n",
    "        gym_env, # an openai gym environment\n",
    "        current_Q = Dict() # current estimation of Q\n",
    "        ; # the rest are keyword argument, not positional arguments\n",
    "        preprocess_state = x -> x, # state preprocessing, identity by default\n",
    "        learning_rate = 0.1,\n",
    "        discount_rate = 0.999,\n",
    "        exploration_rate = 0.1,\n",
    "        render = false, # show game visualization (slower when rendering...)\n",
    "    )\n",
    "    # Rename variables for formula simplicity following Sutton\n",
    "    ϵ, α, γ = exploration_rate, learning_rate, discount_rate\n",
    "    action_space = 0:(gym_env[:action_space][:n] - 1)\n",
    "    Q = deepcopy(current_Q) # Q will store the improved Q estimate\n",
    "    # Reset environment\n",
    "    state = gym_env[:reset]() # regresa el ambiente al comienzo de un episodio\n",
    "    state = preprocess_state(state)\n",
    "    render && gym_env[:render]() # si render es true, crea la visualizacion del estado del juego\n",
    "    # Get initial action\n",
    "    action = policy(state, action_space, Q, ϵ) # selecionar accion con politica\n",
    "    !haskey(Q, (state, action)) && (Q[(state, action)] = 0.) # add key if missing\n",
    "    # Episode iteration information\n",
    "    done = false # sera true cuando termine el episodio\n",
    "    ep_reward = 0. # iniciar pago total en el episodio\n",
    "    ep_steps = 0 # iniciar pasos totales en el episodio\n",
    "    while !done \n",
    "        # Simulate transition\n",
    "        new_state, reward, done, info = gym_env[:step](action) # simula una transicion\n",
    "        new_state = preprocess_state(new_state)\n",
    "        new_action = policy(new_state, action_space, Q, ϵ) # selecionar accion con politica\n",
    "        !haskey(Q, (new_state, new_action)) && (Q[(new_state, new_action)] = 0.) # add key if missing\n",
    "        # Compute δ\n",
    "        δ = reward + γ*Q[(new_state, new_action)]  - Q[(state, action)] \n",
    "        # Update Q \n",
    "        Q[(state, action)] = Q[(state, action)] + α*δ\n",
    "        # Change new states to old states for next step\n",
    "        state = new_state\n",
    "        action = new_action\n",
    "        # Save step information and render if needed\n",
    "        render && gym_env[:render]()\n",
    "        ep_reward += reward # agrega el pago de la transicion al pago del ep.\n",
    "        ep_steps += 1 # agrega un paso al total de pasos en el episodio\n",
    "    end\n",
    "    render && gym_env[:render](close = true)\n",
    "    return Q, ep_reward, ep_steps\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJEMPLO DE USO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict{Any,Any}(Pair{Any,Any}((Float32[-0.6,0.01],0),-1.43484),Pair{Any,Any}((Float32[-0.36,-0.01],1),-0.394279),Pair{Any,Any}((Float32[-0.6,-0.01],2),-1.62576),Pair{Any,Any}((Float32[-0.48,0.01],1),-0.97658),Pair{Any,Any}((Float32[-0.6,-0.01],0),-1.74093),Pair{Any,Any}((Float32[-0.48,-0.01],1),-1.51835),Pair{Any,Any}((Float32[-0.6,-0.01],1),-1.5871),Pair{Any,Any}((Float32[-0.36,-0.01],2),-0.438917),Pair{Any,Any}((Float32[-0.48,0.01],0),-0.861043),Pair{Any,Any}((Float32[-0.48,-0.01],0),-1.42729)…),-200.0,200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = Dict()\n",
    "Q, reward, steps = learn_episode_with_sarsa(mountain_car, Q, preprocess_state = preprocess, render = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APRENDIENDO DE MUCHOS EPISODIOS Y REDUCIENDO TASA DE EXPLORACION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will train a gym environment for many episodes using sarsa and a preprocess\n",
    "function given by the user, defaults to identity.\n",
    "\"\"\"\n",
    "function learn_episodes_with_sarsa(\n",
    "        n_episodes, # number of episodes\n",
    "        gym_env, # an openai gym environment\n",
    "        current_Q = Dict() # current estimation of Q\n",
    "        ; # the rest are keyword argument, not positional arguments\n",
    "        preprocess_state = x -> x, # state preprocessing, identity by default\n",
    "        learning_rate = 0.1,\n",
    "        discount_rate = 0.999,\n",
    "        exploration_rate = 0.1,\n",
    "        exploration_decay =  1 - log(2) / n_episodes, # se reducira a la mitad al final del episodio\n",
    "        render = false, # show game visualization (slower when rendering...)\n",
    "        verbose = true\n",
    "    )\n",
    "    Q = deepcopy(current_Q)\n",
    "    # Iterate episodes\n",
    "    reward_history = []\n",
    "    steps_history = []\n",
    "    for i in 1:n_episodes\n",
    "        # learn from episode\n",
    "        Q, reward, steps = learn_episode_with_sarsa(gym_env, Q, \n",
    "                                                    learning_rate = learning_rate, \n",
    "                                                    discount_rate = discount_rate, \n",
    "                                                    exploration_rate = exploration_rate, \n",
    "                                                    render = render,\n",
    "                                                    preprocess_state = preprocess_state)\n",
    "        verbose && println(\"Episodio \", i, \" con pago \", reward)\n",
    "        # reduce exploration_rate\n",
    "        exploration_rate *= exploration_decay\n",
    "        # save episode information\n",
    "        push!(reward_history, reward)\n",
    "        push!(steps_history, steps)\n",
    "    end\n",
    "    return Q, reward_history, steps_history\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1 con pago -200.0\n",
      "Episodio 2 con pago -200.0\n",
      "Episodio 3 con pago -200.0\n",
      "Episodio 4 con pago -200.0\n",
      "Episodio 5 con pago -200.0\n",
      "Episodio 6 con pago -200.0\n",
      "Episodio 7 con pago -200.0\n",
      "Episodio 8 con pago -200.0\n",
      "Episodio 9 con pago -200.0\n",
      "Episodio 10 con pago -200.0\n",
      "Episodio 11 con pago -200.0\n",
      "Episodio 12 con pago -200.0\n",
      "Episodio 13 con pago -200.0\n",
      "Episodio 14 con pago -200.0\n",
      "Episodio 15 con pago -200.0\n",
      "Episodio 16 con pago -200.0\n",
      "Episodio 17 con pago -200.0\n",
      "Episodio 18 con pago -200.0\n",
      "Episodio 19 con pago -200.0\n",
      "Episodio 20 con pago -200.0\n",
      "Episodio 21 con pago -200.0\n",
      "Episodio 22 con pago -200.0\n",
      "Episodio 23 con pago -200.0\n",
      "Episodio 24 con pago -200.0\n",
      "Episodio 25 con pago -200.0\n",
      "Episodio 26 con pago -200.0\n",
      "Episodio 27 con pago -200.0\n",
      "Episodio 28 con pago -200.0\n",
      "Episodio 29 con pago -200.0\n",
      "Episodio 30 con pago -200.0\n",
      "Episodio 31 con pago -200.0\n",
      "Episodio 32 con pago -200.0\n",
      "Episodio 33 con pago -200.0\n",
      "Episodio 34 con pago -200.0\n",
      "Episodio 35 con pago -200.0\n",
      "Episodio 36 con pago -200.0\n",
      "Episodio 37 con pago -200.0\n",
      "Episodio 38 con pago -200.0\n",
      "Episodio 39 con pago -200.0\n",
      "Episodio 40 con pago -200.0\n",
      "Episodio 41 con pago -200.0\n",
      "Episodio 42 con pago -200.0\n",
      "Episodio 43 con pago -200.0\n",
      "Episodio 44 con pago -200.0\n",
      "Episodio 45 con pago -200.0\n",
      "Episodio 46 con pago -200.0\n",
      "Episodio 47 con pago -200.0\n",
      "Episodio 48 con pago -200.0\n",
      "Episodio 49 con pago -200.0\n",
      "Episodio 50 con pago -200.0\n",
      "Episodio 51 con pago -200.0\n",
      "Episodio 52 con pago -200.0\n",
      "Episodio 53 con pago -200.0\n",
      "Episodio 54 con pago -200.0\n",
      "Episodio 55 con pago -200.0\n",
      "Episodio 56 con pago -200.0\n",
      "Episodio 57 con pago -200.0\n",
      "Episodio 58 con pago -200.0\n",
      "Episodio 59 con pago -200.0\n",
      "Episodio 60 con pago -200.0\n",
      "Episodio 61 con pago -200.0\n",
      "Episodio 62 con pago -200.0\n",
      "Episodio 63 con pago -200.0\n",
      "Episodio 64 con pago -200.0\n",
      "Episodio 65 con pago -200.0\n",
      "Episodio 66 con pago -200.0\n",
      "Episodio 67 con pago -200.0\n",
      "Episodio 68 con pago -200.0\n",
      "Episodio 69 con pago -200.0\n",
      "Episodio 70 con pago -200.0\n",
      "Episodio 71 con pago -200.0\n",
      "Episodio 72 con pago -200.0\n",
      "Episodio 73 con pago -200.0\n",
      "Episodio 74 con pago -200.0\n",
      "Episodio 75 con pago -200.0\n",
      "Episodio 76 con pago -200.0\n",
      "Episodio 77 con pago -200.0\n",
      "Episodio 78 con pago -200.0\n",
      "Episodio 79 con pago -200.0\n",
      "Episodio 80 con pago -200.0\n",
      "Episodio 81 con pago -200.0\n",
      "Episodio 82 con pago -200.0\n",
      "Episodio 83 con pago -200.0\n",
      "Episodio 84 con pago -200.0\n",
      "Episodio 85 con pago -200.0\n",
      "Episodio 86 con pago -200.0\n",
      "Episodio 87 con pago -200.0\n",
      "Episodio 88 con pago -200.0\n",
      "Episodio 89 con pago -200.0\n",
      "Episodio 90 con pago -200.0\n",
      "Episodio 91 con pago -200.0\n",
      "Episodio 92 con pago -200.0\n",
      "Episodio 93 con pago -200.0\n",
      "Episodio 94 con pago -200.0\n",
      "Episodio 95 con pago -200.0\n",
      "Episodio 96 con pago -200.0\n",
      "Episodio 97 con pago -200.0\n",
      "Episodio 98 con pago -200.0\n",
      "Episodio 99 con pago -200.0\n",
      "Episodio 100 con pago -200.0\n",
      "Episodio 101 con pago -200.0\n",
      "Episodio 102 con pago -200.0\n",
      "Episodio 103 con pago -200.0\n",
      "Episodio 104 con pago -200.0\n",
      "Episodio 105 con pago -200.0\n",
      "Episodio 106 con pago -200.0\n",
      "Episodio 107 con pago -200.0\n",
      "Episodio 108 con pago -200.0\n",
      "Episodio 109 con pago -200.0\n",
      "Episodio 110 con pago -200.0\n",
      "Episodio 111 con pago -200.0\n",
      "Episodio 112 con pago -200.0\n",
      "Episodio 113 con pago -200.0\n",
      "Episodio 114 con pago -200.0\n",
      "Episodio 115 con pago -200.0\n",
      "Episodio 116 con pago -200.0\n",
      "Episodio 117 con pago -200.0\n",
      "Episodio 118 con pago -200.0\n",
      "Episodio 119 con pago -200.0\n",
      "Episodio 120 con pago -200.0\n",
      "Episodio 121 con pago -200.0\n",
      "Episodio 122 con pago -200.0\n",
      "Episodio 123 con pago -200.0\n",
      "Episodio 124 con pago -200.0\n",
      "Episodio 125 con pago -200.0\n",
      "Episodio 126 con pago -200.0\n",
      "Episodio 127 con pago -200.0\n",
      "Episodio 128 con pago -200.0\n",
      "Episodio 129 con pago -200.0\n",
      "Episodio 130 con pago -200.0\n",
      "Episodio 131 con pago -200.0\n",
      "Episodio 132 con pago -200.0\n",
      "Episodio 133 con pago -200.0\n",
      "Episodio 134 con pago -200.0\n",
      "Episodio 135 con pago -200.0\n",
      "Episodio 136 con pago -200.0\n",
      "Episodio 137 con pago -200.0\n",
      "Episodio 138 con pago -200.0\n",
      "Episodio 139 con pago -200.0\n",
      "Episodio 140 con pago -200.0\n",
      "Episodio 141 con pago -200.0\n",
      "Episodio 142 con pago -200.0\n",
      "Episodio 143 con pago -200.0\n",
      "Episodio 144 con pago -200.0\n",
      "Episodio 145 con pago -200.0\n",
      "Episodio 146 con pago -200.0\n",
      "Episodio 147 con pago -200.0\n",
      "Episodio 148 con pago -200.0\n",
      "Episodio 149 con pago -200.0\n",
      "Episodio 150 con pago -200.0\n",
      "Episodio 151 con pago -200.0\n",
      "Episodio 152 con pago -200.0\n",
      "Episodio 153 con pago -200.0\n",
      "Episodio 154 con pago -200.0\n",
      "Episodio 155 con pago -200.0\n",
      "Episodio 156 con pago -200.0\n",
      "Episodio 157 con pago -200.0\n",
      "Episodio 158 con pago -200.0\n",
      "Episodio 159 con pago -200.0\n",
      "Episodio 160 con pago -200.0\n",
      "Episodio 161 con pago -200.0\n",
      "Episodio 162 con pago -200.0\n",
      "Episodio 163 con pago -200.0\n",
      "Episodio 164 con pago -200.0\n",
      "Episodio 165 con pago -200.0\n",
      "Episodio 166 con pago -200.0\n",
      "Episodio 167 con pago -200.0\n",
      "Episodio 168 con pago -200.0\n",
      "Episodio 169 con pago -200.0\n",
      "Episodio 170 con pago -200.0\n",
      "Episodio 171 con pago -200.0\n",
      "Episodio 172 con pago -200.0\n",
      "Episodio 173 con pago -200.0\n",
      "Episodio 174 con pago -200.0\n",
      "Episodio 175 con pago -200.0\n",
      "Episodio 176 con pago -200.0\n",
      "Episodio 177 con pago -200.0\n",
      "Episodio 178 con pago -200.0\n",
      "Episodio 179 con pago -200.0\n",
      "Episodio 180 con pago -200.0\n",
      "Episodio 181 con pago -200.0\n",
      "Episodio 182 con pago -200.0\n",
      "Episodio 183 con pago -200.0\n",
      "Episodio 184 con pago -200.0\n",
      "Episodio 185 con pago -200.0\n",
      "Episodio 186 con pago -200.0\n",
      "Episodio 187 con pago -200.0\n",
      "Episodio 188 con pago -200.0\n",
      "Episodio 189 con pago -200.0\n",
      "Episodio 190 con pago -200.0\n",
      "Episodio 191 con pago -200.0\n",
      "Episodio 192 con pago -200.0\n",
      "Episodio 193 con pago -200.0\n",
      "Episodio 194 con pago -200.0\n",
      "Episodio 195 con pago -200.0\n",
      "Episodio 196 con pago -200.0\n",
      "Episodio 197 con pago -200.0\n",
      "Episodio 198 con pago -200.0\n",
      "Episodio 199 con pago -200.0\n",
      "Episodio 200 con pago -200.0\n",
      "Episodio 201 con pago -200.0\n",
      "Episodio 202 con pago -200.0\n",
      "Episodio 203 con pago -200.0\n",
      "Episodio 204 con pago -200.0\n",
      "Episodio 205 con pago -200.0\n",
      "Episodio 206 con pago -200.0\n",
      "Episodio 207 con pago -200.0\n",
      "Episodio 208 con pago -200.0\n",
      "Episodio 209 con pago -200.0\n",
      "Episodio 210 con pago -200.0\n",
      "Episodio 211 con pago -200.0\n",
      "Episodio 212 con pago -200.0\n",
      "Episodio 213 con pago -200.0\n",
      "Episodio 214 con pago -200.0\n",
      "Episodio 215 con pago -200.0\n",
      "Episodio 216 con pago -200.0\n",
      "Episodio 217 con pago -200.0\n",
      "Episodio 218 con pago -200.0\n",
      "Episodio 219 con pago -200.0\n",
      "Episodio 220 con pago -200.0\n",
      "Episodio 221 con pago -200.0\n",
      "Episodio 222 con pago -200.0\n",
      "Episodio 223 con pago -200.0\n",
      "Episodio 224 con pago -200.0\n",
      "Episodio 225 con pago -200.0\n",
      "Episodio 226 con pago -200.0\n",
      "Episodio 227 con pago -200.0\n",
      "Episodio 228 con pago -200.0\n",
      "Episodio 229 con pago -200.0\n",
      "Episodio 230 con pago -200.0\n",
      "Episodio 231 con pago -200.0\n",
      "Episodio 232 con pago -200.0\n",
      "Episodio 233 con pago -200.0\n",
      "Episodio 234 con pago -200.0\n",
      "Episodio 235 con pago -200.0\n",
      "Episodio 236 con pago -200.0\n",
      "Episodio 237 con pago -200.0\n",
      "Episodio 238 con pago -200.0\n",
      "Episodio 239 con pago -200.0\n",
      "Episodio 240 con pago -200.0\n",
      "Episodio 241 con pago -200.0\n",
      "Episodio 242 con pago -200.0\n",
      "Episodio 243 con pago -200.0\n",
      "Episodio 244 con pago -200.0\n",
      "Episodio 245 con pago -200.0\n",
      "Episodio 246 con pago -200.0\n",
      "Episodio 247 con pago -200.0\n",
      "Episodio 248 con pago -200.0\n",
      "Episodio 249 con pago -200.0\n",
      "Episodio 250 con pago -200.0\n",
      "Episodio 251 con pago -200.0\n",
      "Episodio 252 con pago -200.0\n",
      "Episodio 253 con pago -200.0\n",
      "Episodio 254 con pago -200.0\n",
      "Episodio 255 con pago -200.0\n",
      "Episodio 256 con pago -200.0\n",
      "Episodio 257 con pago -200.0\n",
      "Episodio 258 con pago -200.0\n",
      "Episodio 259 con pago -200.0\n",
      "Episodio 260 con pago -200.0\n",
      "Episodio 261 con pago -200.0\n",
      "Episodio 262 con pago -200.0\n",
      "Episodio 263 con pago -200.0\n",
      "Episodio 264 con pago -200.0\n",
      "Episodio 265 con pago -200.0\n",
      "Episodio 266 con pago -200.0\n",
      "Episodio 267 con pago -200.0\n",
      "Episodio 268 con pago -200.0\n",
      "Episodio 269 con pago -200.0\n",
      "Episodio 270 con pago -200.0\n",
      "Episodio 271 con pago -200.0\n",
      "Episodio 272 con pago -200.0\n",
      "Episodio 273 con pago -200.0\n",
      "Episodio 274 con pago -200.0\n",
      "Episodio 275 con pago -200.0\n",
      "Episodio 276 con pago -200.0\n",
      "Episodio 277 con pago -200.0\n",
      "Episodio 278 con pago -200.0\n",
      "Episodio 279 con pago -200.0\n",
      "Episodio 280 con pago -200.0\n",
      "Episodio 281 con pago -200.0\n",
      "Episodio 282 con pago -200.0\n",
      "Episodio 283 con pago -200.0\n",
      "Episodio 284 con pago -200.0\n",
      "Episodio 285 con pago -200.0\n",
      "Episodio 286 con pago -200.0\n",
      "Episodio 287 con pago -200.0\n",
      "Episodio 288 con pago -200.0\n",
      "Episodio 289 con pago -200.0\n",
      "Episodio 290 con pago -200.0\n",
      "Episodio 291 con pago -200.0\n",
      "Episodio 292 con pago -200.0\n",
      "Episodio 293 con pago -200.0\n",
      "Episodio 294 con pago -200.0\n",
      "Episodio 295 con pago -200.0\n",
      "Episodio 296 con pago -200.0\n",
      "Episodio 297 con pago -200.0\n",
      "Episodio 298 con pago -200.0\n",
      "Episodio 299 con pago -200.0\n",
      "Episodio 300 con pago -200.0\n",
      "Episodio 301 con pago -165.0\n",
      "Episodio 302 con pago -200.0\n",
      "Episodio 303 con pago -200.0\n",
      "Episodio 304 con pago -200.0\n",
      "Episodio 305 con pago -174.0\n",
      "Episodio 306 con pago -200.0\n",
      "Episodio 307 con pago -200.0\n",
      "Episodio 308 con pago -200.0\n",
      "Episodio 309 con pago -200.0\n",
      "Episodio 310 con pago -200.0\n",
      "Episodio 311 con pago -200.0\n",
      "Episodio 312 con pago -200.0\n",
      "Episodio 313 con pago -200.0\n",
      "Episodio 314 con pago -200.0\n",
      "Episodio 315 con pago -200.0\n",
      "Episodio 316 con pago -200.0\n",
      "Episodio 317 con pago -200.0\n",
      "Episodio 318 con pago -200.0\n",
      "Episodio 319 con pago -200.0\n",
      "Episodio 320 con pago -200.0\n",
      "Episodio 321 con pago -200.0\n",
      "Episodio 322 con pago -200.0\n",
      "Episodio 323 con pago -200.0\n",
      "Episodio 324 con pago -200.0\n",
      "Episodio 325 con pago -200.0\n",
      "Episodio 326 con pago -200.0\n",
      "Episodio 327 con pago -200.0\n",
      "Episodio 328 con pago -200.0\n",
      "Episodio 329 con pago -200.0\n",
      "Episodio 330 con pago -200.0\n",
      "Episodio 331 con pago -200.0\n",
      "Episodio 332 con pago -200.0\n",
      "Episodio 333 con pago -200.0\n",
      "Episodio 334 con pago -200.0\n",
      "Episodio 335 con pago -200.0\n",
      "Episodio 336 con pago -200.0\n",
      "Episodio 337 con pago -200.0\n",
      "Episodio 338 con pago -200.0\n",
      "Episodio 339 con pago -200.0\n",
      "Episodio 340 con pago -200.0\n",
      "Episodio 341 con pago -200.0\n",
      "Episodio 342 con pago -200.0\n",
      "Episodio 343 con pago -200.0\n",
      "Episodio 344 con pago -200.0\n",
      "Episodio 345 con pago -200.0\n",
      "Episodio 346 con pago -200.0\n",
      "Episodio 347 con pago -200.0\n",
      "Episodio 348 con pago -200.0\n",
      "Episodio 349 con pago -200.0\n",
      "Episodio 350 con pago -200.0\n",
      "Episodio 351 con pago -200.0\n",
      "Episodio 352 con pago -200.0\n",
      "Episodio 353 con pago -200.0\n",
      "Episodio 354 con pago -200.0\n",
      "Episodio 355 con pago -200.0\n",
      "Episodio 356 con pago -200.0\n",
      "Episodio 357 con pago -200.0\n",
      "Episodio 358 con pago -200.0\n",
      "Episodio 359 con pago -200.0\n",
      "Episodio 360 con pago -200.0\n",
      "Episodio 361 con pago -200.0\n",
      "Episodio 362 con pago -200.0\n",
      "Episodio 363 con pago -200.0\n",
      "Episodio 364 con pago -187.0\n",
      "Episodio 365 con pago -200.0\n",
      "Episodio 366 con pago -200.0\n",
      "Episodio 367 con pago -200.0\n",
      "Episodio 368 con pago -200.0\n",
      "Episodio 369 con pago -200.0\n",
      "Episodio 370 con pago -200.0\n",
      "Episodio 371 con pago -200.0\n",
      "Episodio 372 con pago -200.0\n",
      "Episodio 373 con pago -200.0\n",
      "Episodio 374 con pago -200.0\n",
      "Episodio 375 con pago -200.0\n",
      "Episodio 376 con pago -200.0\n",
      "Episodio 377 con pago -200.0\n",
      "Episodio 378 con pago -200.0\n",
      "Episodio 379 con pago -200.0\n",
      "Episodio 380 con pago -200.0\n",
      "Episodio 381 con pago -200.0\n",
      "Episodio 382 con pago -200.0\n",
      "Episodio 383 con pago -200.0\n",
      "Episodio 384 con pago -200.0\n",
      "Episodio 385 con pago -200.0\n",
      "Episodio 386 con pago -200.0\n",
      "Episodio 387 con pago -200.0\n",
      "Episodio 388 con pago -200.0\n",
      "Episodio 389 con pago -200.0\n",
      "Episodio 390 con pago -200.0\n",
      "Episodio 391 con pago -200.0\n",
      "Episodio 392 con pago -200.0\n",
      "Episodio 393 con pago -200.0\n",
      "Episodio 394 con pago -200.0\n",
      "Episodio 395 con pago -200.0\n",
      "Episodio 396 con pago -200.0\n",
      "Episodio 397 con pago -200.0\n",
      "Episodio 398 con pago -200.0\n",
      "Episodio 399 con pago -200.0\n",
      "Episodio 400 con pago -200.0\n",
      "Episodio 401 con pago -200.0\n",
      "Episodio 402 con pago -200.0\n",
      "Episodio 403 con pago -200.0\n",
      "Episodio 404 con pago -200.0\n",
      "Episodio 405 con pago -200.0\n",
      "Episodio 406 con pago -200.0\n",
      "Episodio 407 con pago -200.0\n",
      "Episodio 408 con pago -200.0\n",
      "Episodio 409 con pago -200.0\n",
      "Episodio 410 con pago -200.0\n",
      "Episodio 411 con pago -200.0\n",
      "Episodio 412 con pago -200.0\n",
      "Episodio 413 con pago -200.0\n",
      "Episodio 414 con pago -200.0\n",
      "Episodio 415 con pago -200.0\n",
      "Episodio 416 con pago -200.0\n",
      "Episodio 417 con pago -200.0\n",
      "Episodio 418 con pago -200.0\n",
      "Episodio 419 con pago -200.0\n",
      "Episodio 420 con pago -200.0\n",
      "Episodio 421 con pago -200.0\n",
      "Episodio 422 con pago -200.0\n",
      "Episodio 423 con pago -200.0\n",
      "Episodio 424 con pago -159.0\n",
      "Episodio 425 con pago -200.0\n",
      "Episodio 426 con pago -166.0\n",
      "Episodio 427 con pago -200.0\n",
      "Episodio 428 con pago -200.0\n",
      "Episodio 429 con pago -200.0\n",
      "Episodio 430 con pago -200.0\n",
      "Episodio 431 con pago -200.0\n",
      "Episodio 432 con pago -200.0\n",
      "Episodio 433 con pago -200.0\n",
      "Episodio 434 con pago -200.0\n",
      "Episodio 435 con pago -200.0\n",
      "Episodio 436 con pago -200.0\n",
      "Episodio 437 con pago -200.0\n",
      "Episodio 438 con pago -200.0\n",
      "Episodio 439 con pago -200.0\n",
      "Episodio 440 con pago -200.0\n",
      "Episodio 441 con pago -200.0\n",
      "Episodio 442 con pago -200.0\n",
      "Episodio 443 con pago -200.0\n",
      "Episodio 444 con pago -200.0\n",
      "Episodio 445 con pago -200.0\n",
      "Episodio 446 con pago -200.0\n",
      "Episodio 447 con pago -200.0\n",
      "Episodio 448 con pago -200.0\n",
      "Episodio 449 con pago -200.0\n",
      "Episodio 450 con pago -200.0\n",
      "Episodio 451 con pago -200.0\n",
      "Episodio 452 con pago -200.0\n",
      "Episodio 453 con pago -200.0\n",
      "Episodio 454 con pago -200.0\n",
      "Episodio 455 con pago -200.0\n",
      "Episodio 456 con pago -200.0\n",
      "Episodio 457 con pago -200.0\n",
      "Episodio 458 con pago -200.0\n",
      "Episodio 459 con pago -200.0\n",
      "Episodio 460 con pago -200.0\n",
      "Episodio 461 con pago -200.0\n",
      "Episodio 462 con pago -200.0\n",
      "Episodio 463 con pago -200.0\n",
      "Episodio 464 con pago -200.0\n",
      "Episodio 465 con pago -200.0\n",
      "Episodio 466 con pago -200.0\n",
      "Episodio 467 con pago -200.0\n",
      "Episodio 468 con pago -200.0\n",
      "Episodio 469 con pago -200.0\n",
      "Episodio 470 con pago -200.0\n",
      "Episodio 471 con pago -200.0\n",
      "Episodio 472 con pago -200.0\n",
      "Episodio 473 con pago -200.0\n",
      "Episodio 474 con pago -200.0\n",
      "Episodio 475 con pago -169.0\n",
      "Episodio 476 con pago -200.0\n",
      "Episodio 477 con pago -200.0\n",
      "Episodio 478 con pago -200.0\n",
      "Episodio 479 con pago -200.0\n",
      "Episodio 480 con pago -200.0\n",
      "Episodio 481 con pago -200.0\n",
      "Episodio 482 con pago -200.0\n",
      "Episodio 483 con pago -200.0\n",
      "Episodio 484 con pago -200.0\n",
      "Episodio 485 con pago -200.0\n",
      "Episodio 486 con pago -200.0\n",
      "Episodio 487 con pago -200.0\n",
      "Episodio 488 con pago -200.0\n",
      "Episodio 489 con pago -200.0\n",
      "Episodio 490 con pago -200.0\n",
      "Episodio 491 con pago -200.0\n",
      "Episodio 492 con pago -200.0\n",
      "Episodio 493 con pago -200.0\n",
      "Episodio 494 con pago -165.0\n",
      "Episodio 495 con pago -200.0\n",
      "Episodio 496 con pago -200.0\n",
      "Episodio 497 con pago -200.0\n",
      "Episodio 498 con pago -200.0\n",
      "Episodio 499 con pago -200.0\n",
      "Episodio 500 con pago -200.0\n",
      "Episodio 501 con pago -200.0\n",
      "Episodio 502 con pago -200.0\n",
      "Episodio 503 con pago -200.0\n",
      "Episodio 504 con pago -200.0\n",
      "Episodio 505 con pago -200.0\n",
      "Episodio 506 con pago -200.0\n",
      "Episodio 507 con pago -200.0\n",
      "Episodio 508 con pago -200.0\n",
      "Episodio 509 con pago -200.0\n",
      "Episodio 510 con pago -174.0\n",
      "Episodio 511 con pago -200.0\n",
      "Episodio 512 con pago -200.0\n",
      "Episodio 513 con pago -200.0\n",
      "Episodio 514 con pago -200.0\n",
      "Episodio 515 con pago -200.0\n",
      "Episodio 516 con pago -200.0\n",
      "Episodio 517 con pago -200.0\n",
      "Episodio 518 con pago -200.0\n",
      "Episodio 519 con pago -200.0\n",
      "Episodio 520 con pago -200.0\n",
      "Episodio 521 con pago -200.0\n",
      "Episodio 522 con pago -200.0\n",
      "Episodio 523 con pago -200.0\n",
      "Episodio 524 con pago -200.0\n",
      "Episodio 525 con pago -200.0\n",
      "Episodio 526 con pago -200.0\n",
      "Episodio 527 con pago -200.0\n",
      "Episodio 528 con pago -200.0\n",
      "Episodio 529 con pago -200.0\n",
      "Episodio 530 con pago -200.0\n",
      "Episodio 531 con pago -200.0\n",
      "Episodio 532 con pago -200.0\n",
      "Episodio 533 con pago -200.0\n",
      "Episodio 534 con pago -200.0\n",
      "Episodio 535 con pago -200.0\n",
      "Episodio 536 con pago -200.0\n",
      "Episodio 537 con pago -200.0\n",
      "Episodio 538 con pago -200.0\n",
      "Episodio 539 con pago -200.0\n",
      "Episodio 540 con pago -200.0\n",
      "Episodio 541 con pago -200.0\n",
      "Episodio 542 con pago -200.0\n",
      "Episodio 543 con pago -200.0\n",
      "Episodio 544 con pago -200.0\n",
      "Episodio 545 con pago -200.0\n",
      "Episodio 546 con pago -180.0\n",
      "Episodio 547 con pago -200.0\n",
      "Episodio 548 con pago -200.0\n",
      "Episodio 549 con pago -200.0\n",
      "Episodio 550 con pago -200.0\n",
      "Episodio 551 con pago -200.0\n",
      "Episodio 552 con pago -200.0\n",
      "Episodio 553 con pago -200.0\n",
      "Episodio 554 con pago -200.0\n",
      "Episodio 555 con pago -200.0\n",
      "Episodio 556 con pago -200.0\n",
      "Episodio 557 con pago -200.0\n",
      "Episodio 558 con pago -200.0\n",
      "Episodio 559 con pago -200.0\n",
      "Episodio 560 con pago -200.0\n",
      "Episodio 561 con pago -200.0\n",
      "Episodio 562 con pago -200.0\n",
      "Episodio 563 con pago -174.0\n",
      "Episodio 564 con pago -200.0\n",
      "Episodio 565 con pago -200.0\n",
      "Episodio 566 con pago -200.0\n",
      "Episodio 567 con pago -200.0\n",
      "Episodio 568 con pago -200.0\n",
      "Episodio 569 con pago -200.0\n",
      "Episodio 570 con pago -200.0\n",
      "Episodio 571 con pago -200.0\n",
      "Episodio 572 con pago -200.0\n",
      "Episodio 573 con pago -200.0\n",
      "Episodio 574 con pago -200.0\n",
      "Episodio 575 con pago -200.0\n",
      "Episodio 576 con pago -200.0\n",
      "Episodio 577 con pago -200.0\n",
      "Episodio 578 con pago -200.0\n",
      "Episodio 579 con pago -200.0\n",
      "Episodio 580 con pago -200.0\n",
      "Episodio 581 con pago -200.0\n",
      "Episodio 582 con pago -200.0\n",
      "Episodio 583 con pago -200.0\n",
      "Episodio 584 con pago -200.0\n",
      "Episodio 585 con pago -200.0\n",
      "Episodio 586 con pago -200.0\n",
      "Episodio 587 con pago -200.0\n",
      "Episodio 588 con pago -200.0\n",
      "Episodio 589 con pago -200.0\n",
      "Episodio 590 con pago -200.0\n",
      "Episodio 591 con pago -200.0\n",
      "Episodio 592 con pago -200.0\n",
      "Episodio 593 con pago -200.0\n",
      "Episodio 594 con pago -200.0\n",
      "Episodio 595 con pago -200.0\n",
      "Episodio 596 con pago -200.0\n",
      "Episodio 597 con pago -200.0\n",
      "Episodio 598 con pago -200.0\n",
      "Episodio 599 con pago -200.0\n",
      "Episodio 600 con pago -200.0\n",
      "Episodio 601 con pago -200.0\n",
      "Episodio 602 con pago -200.0\n",
      "Episodio 603 con pago -200.0\n",
      "Episodio 604 con pago -200.0\n",
      "Episodio 605 con pago -200.0\n",
      "Episodio 606 con pago -200.0\n",
      "Episodio 607 con pago -200.0\n",
      "Episodio 608 con pago -200.0\n",
      "Episodio 609 con pago -200.0\n",
      "Episodio 610 con pago -200.0\n",
      "Episodio 611 con pago -200.0\n",
      "Episodio 612 con pago -200.0\n",
      "Episodio 613 con pago -200.0\n",
      "Episodio 614 con pago -200.0\n",
      "Episodio 615 con pago -200.0\n",
      "Episodio 616 con pago -200.0\n",
      "Episodio 617 con pago -200.0\n",
      "Episodio 618 con pago -200.0\n",
      "Episodio 619 con pago -200.0\n",
      "Episodio 620 con pago -200.0\n",
      "Episodio 621 con pago -168.0\n",
      "Episodio 622 con pago -164.0\n",
      "Episodio 623 con pago -200.0\n",
      "Episodio 624 con pago -157.0\n",
      "Episodio 625 con pago -200.0\n",
      "Episodio 626 con pago -200.0\n",
      "Episodio 627 con pago -200.0\n",
      "Episodio 628 con pago -200.0\n",
      "Episodio 629 con pago -200.0\n",
      "Episodio 630 con pago -168.0\n",
      "Episodio 631 con pago -200.0\n",
      "Episodio 632 con pago -200.0\n",
      "Episodio 633 con pago -150.0\n",
      "Episodio 634 con pago -167.0\n",
      "Episodio 635 con pago -165.0\n",
      "Episodio 636 con pago -200.0\n",
      "Episodio 637 con pago -169.0\n",
      "Episodio 638 con pago -200.0\n",
      "Episodio 639 con pago -200.0\n",
      "Episodio 640 con pago -171.0\n",
      "Episodio 641 con pago -200.0\n",
      "Episodio 642 con pago -200.0\n",
      "Episodio 643 con pago -200.0\n",
      "Episodio 644 con pago -154.0\n",
      "Episodio 645 con pago -200.0\n",
      "Episodio 646 con pago -200.0\n",
      "Episodio 647 con pago -200.0\n",
      "Episodio 648 con pago -200.0\n",
      "Episodio 649 con pago -159.0\n",
      "Episodio 650 con pago -169.0\n",
      "Episodio 651 con pago -168.0\n",
      "Episodio 652 con pago -199.0\n",
      "Episodio 653 con pago -200.0\n",
      "Episodio 654 con pago -200.0\n",
      "Episodio 655 con pago -200.0\n",
      "Episodio 656 con pago -200.0\n",
      "Episodio 657 con pago -200.0\n",
      "Episodio 658 con pago -200.0\n",
      "Episodio 659 con pago -200.0\n",
      "Episodio 660 con pago -200.0\n",
      "Episodio 661 con pago -200.0\n",
      "Episodio 662 con pago -200.0\n",
      "Episodio 663 con pago -200.0\n",
      "Episodio 664 con pago -200.0\n",
      "Episodio 665 con pago -200.0\n",
      "Episodio 666 con pago -200.0\n",
      "Episodio 667 con pago -200.0\n",
      "Episodio 668 con pago -200.0\n",
      "Episodio 669 con pago -200.0\n",
      "Episodio 670 con pago -200.0\n",
      "Episodio 671 con pago -200.0\n",
      "Episodio 672 con pago -200.0\n",
      "Episodio 673 con pago -200.0\n",
      "Episodio 674 con pago -200.0\n",
      "Episodio 675 con pago -200.0\n",
      "Episodio 676 con pago -200.0\n",
      "Episodio 677 con pago -200.0\n",
      "Episodio 678 con pago -200.0\n",
      "Episodio 679 con pago -200.0\n",
      "Episodio 680 con pago -200.0\n",
      "Episodio 681 con pago -200.0\n",
      "Episodio 682 con pago -200.0\n",
      "Episodio 683 con pago -200.0\n",
      "Episodio 684 con pago -200.0\n",
      "Episodio 685 con pago -200.0\n",
      "Episodio 686 con pago -200.0\n",
      "Episodio 687 con pago -200.0\n",
      "Episodio 688 con pago -200.0\n",
      "Episodio 689 con pago -200.0\n",
      "Episodio 690 con pago -200.0\n",
      "Episodio 691 con pago -200.0\n",
      "Episodio 692 con pago -200.0\n",
      "Episodio 693 con pago -200.0\n",
      "Episodio 694 con pago -200.0\n",
      "Episodio 695 con pago -200.0\n",
      "Episodio 696 con pago -200.0\n",
      "Episodio 697 con pago -200.0\n",
      "Episodio 698 con pago -200.0\n",
      "Episodio 699 con pago -200.0\n",
      "Episodio 700 con pago -200.0\n",
      "Episodio 701 con pago -200.0\n",
      "Episodio 702 con pago -200.0\n",
      "Episodio 703 con pago -200.0\n",
      "Episodio 704 con pago -200.0\n",
      "Episodio 705 con pago -200.0\n",
      "Episodio 706 con pago -200.0\n",
      "Episodio 707 con pago -200.0\n",
      "Episodio 708 con pago -200.0\n",
      "Episodio 709 con pago -200.0\n",
      "Episodio 710 con pago -200.0\n",
      "Episodio 711 con pago -200.0\n",
      "Episodio 712 con pago -200.0\n",
      "Episodio 713 con pago -200.0\n",
      "Episodio 714 con pago -200.0\n",
      "Episodio 715 con pago -200.0\n",
      "Episodio 716 con pago -158.0\n",
      "Episodio 717 con pago -200.0\n",
      "Episodio 718 con pago -200.0\n",
      "Episodio 719 con pago -200.0\n",
      "Episodio 720 con pago -200.0\n",
      "Episodio 721 con pago -200.0\n",
      "Episodio 722 con pago -200.0\n",
      "Episodio 723 con pago -170.0\n",
      "Episodio 724 con pago -156.0\n",
      "Episodio 725 con pago -181.0\n",
      "Episodio 726 con pago -200.0\n",
      "Episodio 727 con pago -200.0\n",
      "Episodio 728 con pago -200.0\n",
      "Episodio 729 con pago -200.0\n",
      "Episodio 730 con pago -200.0\n",
      "Episodio 731 con pago -200.0\n",
      "Episodio 732 con pago -200.0\n",
      "Episodio 733 con pago -200.0\n",
      "Episodio 734 con pago -200.0\n",
      "Episodio 735 con pago -200.0\n",
      "Episodio 736 con pago -200.0\n",
      "Episodio 737 con pago -194.0\n",
      "Episodio 738 con pago -200.0\n",
      "Episodio 739 con pago -200.0\n",
      "Episodio 740 con pago -200.0\n",
      "Episodio 741 con pago -200.0\n",
      "Episodio 742 con pago -200.0\n",
      "Episodio 743 con pago -200.0\n",
      "Episodio 744 con pago -200.0\n",
      "Episodio 745 con pago -200.0\n",
      "Episodio 746 con pago -200.0\n",
      "Episodio 747 con pago -200.0\n",
      "Episodio 748 con pago -200.0\n",
      "Episodio 749 con pago -200.0\n",
      "Episodio 750 con pago -186.0\n",
      "Episodio 751 con pago -168.0\n",
      "Episodio 752 con pago -200.0\n",
      "Episodio 753 con pago -200.0\n",
      "Episodio 754 con pago -200.0\n",
      "Episodio 755 con pago -200.0\n",
      "Episodio 756 con pago -200.0\n",
      "Episodio 757 con pago -200.0\n",
      "Episodio 758 con pago -200.0\n",
      "Episodio 759 con pago -197.0\n",
      "Episodio 760 con pago -195.0\n",
      "Episodio 761 con pago -180.0\n",
      "Episodio 762 con pago -151.0\n",
      "Episodio 763 con pago -200.0\n",
      "Episodio 764 con pago -200.0\n",
      "Episodio 765 con pago -200.0\n",
      "Episodio 766 con pago -200.0\n",
      "Episodio 767 con pago -200.0\n",
      "Episodio 768 con pago -200.0\n",
      "Episodio 769 con pago -200.0\n",
      "Episodio 770 con pago -200.0\n",
      "Episodio 771 con pago -200.0\n",
      "Episodio 772 con pago -200.0\n",
      "Episodio 773 con pago -200.0\n",
      "Episodio 774 con pago -200.0\n",
      "Episodio 775 con pago -200.0\n",
      "Episodio 776 con pago -200.0\n",
      "Episodio 777 con pago -200.0\n",
      "Episodio 778 con pago -200.0\n",
      "Episodio 779 con pago -200.0\n",
      "Episodio 780 con pago -200.0\n",
      "Episodio 781 con pago -200.0\n",
      "Episodio 782 con pago -200.0\n",
      "Episodio 783 con pago -200.0\n",
      "Episodio 784 con pago -200.0\n",
      "Episodio 785 con pago -200.0\n",
      "Episodio 786 con pago -200.0\n",
      "Episodio 787 con pago -200.0\n",
      "Episodio 788 con pago -200.0\n",
      "Episodio 789 con pago -200.0\n",
      "Episodio 790 con pago -200.0\n",
      "Episodio 791 con pago -200.0\n",
      "Episodio 792 con pago -200.0\n",
      "Episodio 793 con pago -200.0\n",
      "Episodio 794 con pago -200.0\n",
      "Episodio 795 con pago -200.0\n",
      "Episodio 796 con pago -200.0\n",
      "Episodio 797 con pago -200.0\n",
      "Episodio 798 con pago -200.0\n",
      "Episodio 799 con pago -200.0\n",
      "Episodio 800 con pago -200.0\n",
      "Episodio 801 con pago -200.0\n",
      "Episodio 802 con pago -200.0\n",
      "Episodio 803 con pago -200.0\n",
      "Episodio 804 con pago -200.0\n",
      "Episodio 805 con pago -200.0\n",
      "Episodio 806 con pago -200.0\n",
      "Episodio 807 con pago -200.0\n",
      "Episodio 808 con pago -200.0\n",
      "Episodio 809 con pago -200.0\n",
      "Episodio 810 con pago -200.0\n",
      "Episodio 811 con pago -200.0\n",
      "Episodio 812 con pago -200.0\n",
      "Episodio 813 con pago -200.0\n",
      "Episodio 814 con pago -200.0\n",
      "Episodio 815 con pago -200.0\n",
      "Episodio 816 con pago -200.0\n",
      "Episodio 817 con pago -200.0\n",
      "Episodio 818 con pago -200.0\n",
      "Episodio 819 con pago -200.0\n",
      "Episodio 820 con pago -200.0\n",
      "Episodio 821 con pago -200.0\n",
      "Episodio 822 con pago -200.0\n",
      "Episodio 823 con pago -200.0\n",
      "Episodio 824 con pago -200.0\n",
      "Episodio 825 con pago -200.0\n",
      "Episodio 826 con pago -200.0\n",
      "Episodio 827 con pago -200.0\n",
      "Episodio 828 con pago -200.0\n",
      "Episodio 829 con pago -200.0\n",
      "Episodio 830 con pago -200.0\n",
      "Episodio 831 con pago -200.0\n",
      "Episodio 832 con pago -200.0\n",
      "Episodio 833 con pago -200.0\n",
      "Episodio 834 con pago -200.0\n",
      "Episodio 835 con pago -200.0\n",
      "Episodio 836 con pago -200.0\n",
      "Episodio 837 con pago -200.0\n",
      "Episodio 838 con pago -200.0\n",
      "Episodio 839 con pago -172.0\n",
      "Episodio 840 con pago -161.0\n",
      "Episodio 841 con pago -200.0\n",
      "Episodio 842 con pago -200.0\n",
      "Episodio 843 con pago -200.0\n",
      "Episodio 844 con pago -150.0\n",
      "Episodio 845 con pago -200.0\n",
      "Episodio 846 con pago -200.0\n",
      "Episodio 847 con pago -194.0\n",
      "Episodio 848 con pago -200.0\n",
      "Episodio 849 con pago -200.0\n",
      "Episodio 850 con pago -197.0\n",
      "Episodio 851 con pago -200.0\n",
      "Episodio 852 con pago -200.0\n",
      "Episodio 853 con pago -200.0\n",
      "Episodio 854 con pago -200.0\n",
      "Episodio 855 con pago -200.0\n",
      "Episodio 856 con pago -200.0\n",
      "Episodio 857 con pago -122.0\n",
      "Episodio 858 con pago -200.0\n",
      "Episodio 859 con pago -125.0\n",
      "Episodio 860 con pago -169.0\n",
      "Episodio 861 con pago -200.0\n",
      "Episodio 862 con pago -171.0\n",
      "Episodio 863 con pago -155.0\n",
      "Episodio 864 con pago -200.0\n",
      "Episodio 865 con pago -157.0\n",
      "Episodio 866 con pago -180.0\n",
      "Episodio 867 con pago -160.0\n",
      "Episodio 868 con pago -200.0\n",
      "Episodio 869 con pago -200.0\n",
      "Episodio 870 con pago -200.0\n",
      "Episodio 871 con pago -200.0\n",
      "Episodio 872 con pago -200.0\n",
      "Episodio 873 con pago -200.0\n",
      "Episodio 874 con pago -195.0\n",
      "Episodio 875 con pago -199.0\n",
      "Episodio 876 con pago -200.0\n",
      "Episodio 877 con pago -151.0\n",
      "Episodio 878 con pago -200.0\n",
      "Episodio 879 con pago -175.0\n",
      "Episodio 880 con pago -200.0\n",
      "Episodio 881 con pago -200.0\n",
      "Episodio 882 con pago -200.0\n",
      "Episodio 883 con pago -167.0\n",
      "Episodio 884 con pago -168.0\n",
      "Episodio 885 con pago -168.0\n",
      "Episodio 886 con pago -156.0\n",
      "Episodio 887 con pago -160.0\n",
      "Episodio 888 con pago -141.0\n",
      "Episodio 889 con pago -200.0\n",
      "Episodio 890 con pago -158.0\n",
      "Episodio 891 con pago -161.0\n",
      "Episodio 892 con pago -160.0\n",
      "Episodio 893 con pago -152.0\n",
      "Episodio 894 con pago -155.0\n",
      "Episodio 895 con pago -200.0\n",
      "Episodio 896 con pago -155.0\n",
      "Episodio 897 con pago -200.0\n",
      "Episodio 898 con pago -200.0\n",
      "Episodio 899 con pago -200.0\n",
      "Episodio 900 con pago -145.0\n",
      "Episodio 901 con pago -200.0\n",
      "Episodio 902 con pago -200.0\n",
      "Episodio 903 con pago -200.0\n",
      "Episodio 904 con pago -200.0\n",
      "Episodio 905 con pago -200.0\n",
      "Episodio 906 con pago -164.0\n",
      "Episodio 907 con pago -200.0\n",
      "Episodio 908 con pago -184.0\n",
      "Episodio 909 con pago -195.0\n",
      "Episodio 910 con pago -196.0\n",
      "Episodio 911 con pago -200.0\n",
      "Episodio 912 con pago -200.0\n",
      "Episodio 913 con pago -200.0\n",
      "Episodio 914 con pago -200.0\n",
      "Episodio 915 con pago -200.0\n",
      "Episodio 916 con pago -198.0\n",
      "Episodio 917 con pago -200.0\n",
      "Episodio 918 con pago -200.0\n",
      "Episodio 919 con pago -200.0\n",
      "Episodio 920 con pago -200.0\n",
      "Episodio 921 con pago -200.0\n",
      "Episodio 922 con pago -166.0\n",
      "Episodio 923 con pago -163.0\n",
      "Episodio 924 con pago -200.0\n",
      "Episodio 925 con pago -184.0\n",
      "Episodio 926 con pago -183.0\n",
      "Episodio 927 con pago -185.0\n",
      "Episodio 928 con pago -160.0\n",
      "Episodio 929 con pago -194.0\n",
      "Episodio 930 con pago -200.0\n",
      "Episodio 931 con pago -200.0\n",
      "Episodio 932 con pago -200.0\n",
      "Episodio 933 con pago -200.0\n",
      "Episodio 934 con pago -200.0\n",
      "Episodio 935 con pago -165.0\n",
      "Episodio 936 con pago -200.0\n",
      "Episodio 937 con pago -200.0\n",
      "Episodio 938 con pago -200.0\n",
      "Episodio 939 con pago -200.0\n",
      "Episodio 940 con pago -200.0\n",
      "Episodio 941 con pago -195.0\n",
      "Episodio 942 con pago -200.0\n",
      "Episodio 943 con pago -168.0\n",
      "Episodio 944 con pago -195.0\n",
      "Episodio 945 con pago -162.0\n",
      "Episodio 946 con pago -158.0\n",
      "Episodio 947 con pago -200.0\n",
      "Episodio 948 con pago -160.0\n",
      "Episodio 949 con pago -159.0\n",
      "Episodio 950 con pago -200.0\n",
      "Episodio 951 con pago -157.0\n",
      "Episodio 952 con pago -200.0\n",
      "Episodio 953 con pago -164.0\n",
      "Episodio 954 con pago -160.0\n",
      "Episodio 955 con pago -200.0\n",
      "Episodio 956 con pago -162.0\n",
      "Episodio 957 con pago -193.0\n",
      "Episodio 958 con pago -200.0\n",
      "Episodio 959 con pago -163.0\n",
      "Episodio 960 con pago -160.0\n",
      "Episodio 961 con pago -156.0\n",
      "Episodio 962 con pago -162.0\n",
      "Episodio 963 con pago -157.0\n",
      "Episodio 964 con pago -160.0\n",
      "Episodio 965 con pago -152.0\n",
      "Episodio 966 con pago -158.0\n",
      "Episodio 967 con pago -161.0\n",
      "Episodio 968 con pago -162.0\n",
      "Episodio 969 con pago -156.0\n",
      "Episodio 970 con pago -167.0\n",
      "Episodio 971 con pago -153.0\n",
      "Episodio 972 con pago -154.0\n",
      "Episodio 973 con pago -149.0\n",
      "Episodio 974 con pago -158.0\n",
      "Episodio 975 con pago -154.0\n",
      "Episodio 976 con pago -154.0\n",
      "Episodio 977 con pago -153.0\n",
      "Episodio 978 con pago -146.0\n",
      "Episodio 979 con pago -160.0\n",
      "Episodio 980 con pago -151.0\n",
      "Episodio 981 con pago -142.0\n",
      "Episodio 982 con pago -155.0\n",
      "Episodio 983 con pago -151.0\n",
      "Episodio 984 con pago -144.0\n",
      "Episodio 985 con pago -137.0\n",
      "Episodio 986 con pago -143.0\n",
      "Episodio 987 con pago -151.0\n",
      "Episodio 988 con pago -145.0\n",
      "Episodio 989 con pago -134.0\n",
      "Episodio 990 con pago -140.0\n",
      "Episodio 991 con pago -137.0\n",
      "Episodio 992 con pago -147.0\n",
      "Episodio 993 con pago -151.0\n",
      "Episodio 994 con pago -169.0\n",
      "Episodio 995 con pago -149.0\n",
      "Episodio 996 con pago -152.0\n",
      "Episodio 997 con pago -200.0\n",
      "Episodio 998 con pago -144.0\n",
      "Episodio 999 con pago -200.0\n",
      "Episodio 1000 con pago -200.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dict{Any,Any}(Pair{Any,Any}((Float32[-0.24,-0.05],0),-22.2226),Pair{Any,Any}((Float32[-0.48,-0.07],0),-1.13833),Pair{Any,Any}((Float32[0.36,0.05],2),-2.06681),Pair{Any,Any}((Float32[0.0,0.03],2),-24.3176),Pair{Any,Any}((Float32[-0.96,0.03],0),-30.8016),Pair{Any,Any}((Float32[-1.08,-0.01],0),-34.4823),Pair{Any,Any}((Float32[-0.96,0.03],2),-27.5691),Pair{Any,Any}((Float32[-0.36,0.05],1),-24.4511),Pair{Any,Any}((Float32[0.0,0.05],2),-8.24563),Pair{Any,Any}((Float32[-0.24,-0.03],1),-36.2321)…),Any[-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0  …  -137.0,-147.0,-151.0,-169.0,-149.0,-152.0,-200.0,-144.0,-200.0,-200.0],Any[200,200,200,200,200,200,200,200,200,200  …  137,147,151,169,149,152,200,144,200,200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, reward_history, steps_history = learn_episodes_with_sarsa(\n",
    "    1000, mountain_car, Dict(), \n",
    "    preprocess_state = preprocess,\n",
    "    learning_rate = 0.05,\n",
    "    exploration_rate = 0.25,\n",
    "    exploration_decay = 1 - log(25) / 1000, # will reduce to 0.01 at the end of training\n",
    "    render = true # be patient, enjoy watching, switch to false for speed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJEMPLO DE USO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mINFO: Nothing to be done\n",
      "\u001b[0m\u001b[1m\u001b[34mINFO: METADATA is out-of-date — you may not have the latest version of Plots\n",
      "\u001b[0m\u001b[1m\u001b[34mINFO: Use `Pkg.update()` to get the latest versions of your packages\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 1000-element Array{Any,1} at index [1001:1100]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 1000-element Array{Any,1} at index [1001:1100]",
      "",
      " in throw_boundserror(::Array{Any,1}, ::Tuple{UnitRange{Int64}}) at ./abstractarray.jl:363",
      " in checkbounds at ./abstractarray.jl:292 [inlined]",
      " in getindex(::Array{Any,1}, ::UnitRange{Int64}) at ./array.jl:392",
      " in macro expansion; at ./In[23]:8 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Plots\")\n",
    "#Pkg.add(\"GR\")\n",
    "#Pkg.update()\n",
    "using Plots; gr()\n",
    "plot_every = 100\n",
    "roll_mean = []\n",
    "for i in 1:50\n",
    "   push!(roll_mean, mean(reward_history[(plot_every*(i-1)+1):(plot_every*i)])) \n",
    "end\n",
    "plot(roll_mean, title = \"Retorno promedio en batches de 100 episodios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style='color: red'> Ejercicio 4 </span>\n",
    "\n",
    "1. Replica el codigo anterior de entrenamiento en 5000 episodios haciendo los cambios necesarios para aprender con Q-Learning en vez de SARSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following function plays a gym_episode and learns using Q-Learning. It receives a current estimate of Q and \n",
    "returns an improved estimate Q, the episode reward and the number of steps.\n",
    "\"\"\"\n",
    "function learn_episode_with_qlearning(\n",
    "        gym_env, # an openai gym environment\n",
    "        current_Q = Dict() # current estimation of Q\n",
    "        ; # the rest are keyword argument, not positional arguments\n",
    "        preprocess_state = x -> x, # state preprocessing, identity by default\n",
    "        learning_rate = 0.1,\n",
    "        discount_rate = 0.999,\n",
    "        exploration_rate = 0.1,\n",
    "        render = false, # show game visualization (slower when rendering...)\n",
    "    )\n",
    "    # Rename variables for formula simplicity following Sutton\n",
    "    ϵ, α, γ = exploration_rate, learning_rate, discount_rate\n",
    "    action_space = 0:(gym_env[:action_space][:n] - 1)\n",
    "    Q = deepcopy(current_Q) # Q will store the improved Q estimate\n",
    "    # Reset environment\n",
    "    state = gym_env[:reset]() # regresa el ambiente al comienzo de un episodio\n",
    "    state = preprocess_state(state)\n",
    "    render && gym_env[:render]() # si render es true, crea la visualizacion del estado del juego\n",
    "    # Get initial action\n",
    "    action = policy(state, action_space, Q, ϵ) # selecionar accion con politica\n",
    "    !haskey(Q, (state, action)) && (Q[(state, action)] = 0.) # add key if missing\n",
    "    # Episode iteration information\n",
    "    done = false # sera true cuando termine el episodio\n",
    "    ep_reward = 0. # iniciar pago total en el episodio\n",
    "    ep_steps = 0 # iniciar pasos totales en el episodio\n",
    "    while !done \n",
    "        # Simulate transition\n",
    "        new_state, reward, done, info = gym_env[:step](action) # simula una transicion\n",
    "        new_state = preprocess_state(new_state)\n",
    "        new_action = policy(new_state, action_space, Q, ϵ) # selecionar accion con politica\n",
    "        !haskey(Q, (new_state, new_action)) && (Q[(new_state, new_action)] = 0.) # add key if missing\n",
    "        # Compute δ\n",
    "        max_Q = maximum([get(Q,(new_state,new_action),0.) for a in action_space])#Maximizo y obtengo la política optima\n",
    "        δ = reward + γ*max_Q  - Q[(state, action)] \n",
    "        # Update Q \n",
    "        Q[(state, action)] = Q[(state, action)] + α*δ\n",
    "        # Change new states to old states for next step\n",
    "        state = new_state\n",
    "        action = new_action\n",
    "        # Save step information and render if needed\n",
    "        render && gym_env[:render]()\n",
    "        ep_reward += reward # agrega el pago de la transicion al pago del ep.\n",
    "        ep_steps += 1 # agrega un paso al total de pasos en el episodio\n",
    "    end\n",
    "    render && gym_env[:render](close = true)\n",
    "    return Q, ep_reward, ep_steps\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function learn_episodes_with_qlearning(\n",
    "        n_episodes, # number of episodes\n",
    "        gym_env, # an openai gym environment\n",
    "        current_Q = Dict() # current estimation of Q\n",
    "        ; # the rest are keyword argument, not positional arguments\n",
    "        preprocess_state = x -> x, # state preprocessing, identity by default\n",
    "        learning_rate = 0.1,\n",
    "        discount_rate = 0.999,\n",
    "        exploration_rate = 0.1,\n",
    "        exploration_decay =  1 - log(2) / n_episodes, # se reducira a la mitad al final del episodio\n",
    "        render = false, # show game visualization (slower when rendering...)\n",
    "        verbose = true\n",
    "    )\n",
    "    Q = deepcopy(current_Q)\n",
    "    # Iterate episodes\n",
    "    reward_history = []\n",
    "    steps_history = []\n",
    "    for i in 1:n_episodes\n",
    "        # learn from episode\n",
    "        Q, reward, steps = learn_episode_with_qlearning(gym_env, Q, \n",
    "                                                    learning_rate = learning_rate, \n",
    "                                                    discount_rate = discount_rate, \n",
    "                                                    exploration_rate = exploration_rate, \n",
    "                                                    render = render,\n",
    "                                                    preprocess_state = preprocess_state)\n",
    "        verbose && println(\"Episodio \", i, \" con pago \", reward)\n",
    "        # reduce exploration_rate\n",
    "        exploration_rate *= exploration_decay\n",
    "        # save episode information\n",
    "        push!(reward_history, reward)\n",
    "        push!(steps_history, steps)\n",
    "    end\n",
    "    return Q, reward_history, steps_history\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dict{Any,Any}(Pair{Any,Any}((Float32[-0.6,0.01],0),-1.44984),Pair{Any,Any}((Float32[-0.36,-0.01],1),-0.19999),Pair{Any,Any}((Float32[-0.6,-0.01],2),-1.63394),Pair{Any,Any}((Float32[-0.48,0.01],1),-1.11687),Pair{Any,Any}((Float32[-0.6,-0.01],0),-1.56827),Pair{Any,Any}((Float32[-0.48,-0.01],1),-1.60006),Pair{Any,Any}((Float32[-0.6,-0.01],1),-1.51141),Pair{Any,Any}((Float32[-0.36,-0.01],2),-0.490098),Pair{Any,Any}((Float32[-0.48,0.01],0),-1.09917),Pair{Any,Any}((Float32[-0.48,-0.01],0),-1.49431)…),-200.0,200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = Dict()\n",
    "Q, reward, steps = learn_episode_with_qlearning(mountain_car, Q, preprocess_state = preprocess, render = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1 con pago -200.0\n",
      "Episodio 2 con pago -200.0\n",
      "Episodio 3 con pago -200.0\n",
      "Episodio 4 con pago -200.0\n",
      "Episodio 5 con pago -200.0\n",
      "Episodio 6 con pago -200.0\n",
      "Episodio 7 con pago -200.0\n",
      "Episodio 8 con pago -200.0\n",
      "Episodio 9 con pago -200.0\n",
      "Episodio 10 con pago -200.0\n",
      "Episodio 11 con pago -200.0\n",
      "Episodio 12 con pago -200.0\n",
      "Episodio 13 con pago -200.0\n",
      "Episodio 14 con pago -200.0\n",
      "Episodio 15 con pago -200.0\n",
      "Episodio 16 con pago -200.0\n",
      "Episodio 17 con pago -200.0\n",
      "Episodio 18 con pago -200.0\n",
      "Episodio 19 con pago -200.0\n",
      "Episodio 20 con pago -200.0\n",
      "Episodio 21 con pago -200.0\n",
      "Episodio 22 con pago -200.0\n",
      "Episodio 23 con pago -200.0\n",
      "Episodio 24 con pago -200.0\n",
      "Episodio 25 con pago -200.0\n",
      "Episodio 26 con pago -200.0\n",
      "Episodio 27 con pago -200.0\n",
      "Episodio 28 con pago -200.0\n",
      "Episodio 29 con pago -200.0\n",
      "Episodio 30 con pago -200.0\n",
      "Episodio 31 con pago -200.0\n",
      "Episodio 32 con pago -200.0\n",
      "Episodio 33 con pago -200.0\n",
      "Episodio 34 con pago -200.0\n",
      "Episodio 35 con pago -200.0\n",
      "Episodio 36 con pago -200.0\n",
      "Episodio 37 con pago -200.0\n",
      "Episodio 38 con pago -200.0\n",
      "Episodio 39 con pago -200.0\n",
      "Episodio 40 con pago -200.0\n",
      "Episodio 41 con pago -200.0\n",
      "Episodio 42 con pago -200.0\n",
      "Episodio 43 con pago -200.0\n",
      "Episodio 44 con pago -200.0\n",
      "Episodio 45 con pago -200.0\n",
      "Episodio 46 con pago -200.0\n",
      "Episodio 47 con pago -200.0\n",
      "Episodio 48 con pago -200.0\n",
      "Episodio 49 con pago -200.0\n",
      "Episodio 50 con pago -200.0\n",
      "Episodio 51 con pago -200.0\n",
      "Episodio 52 con pago -200.0\n",
      "Episodio 53 con pago -200.0\n",
      "Episodio 54 con pago -200.0\n",
      "Episodio 55 con pago -200.0\n",
      "Episodio 56 con pago -200.0\n",
      "Episodio 57 con pago -200.0\n",
      "Episodio 58 con pago -200.0\n",
      "Episodio 59 con pago -200.0\n",
      "Episodio 60 con pago -200.0\n",
      "Episodio 61 con pago -200.0\n",
      "Episodio 62 con pago -200.0\n",
      "Episodio 63 con pago -200.0\n",
      "Episodio 64 con pago -200.0\n",
      "Episodio 65 con pago -200.0\n",
      "Episodio 66 con pago -200.0\n",
      "Episodio 67 con pago -200.0\n",
      "Episodio 68 con pago -200.0\n",
      "Episodio 69 con pago -200.0\n",
      "Episodio 70 con pago -200.0\n",
      "Episodio 71 con pago -200.0\n",
      "Episodio 72 con pago -200.0\n",
      "Episodio 73 con pago -200.0\n",
      "Episodio 74 con pago -200.0\n",
      "Episodio 75 con pago -200.0\n",
      "Episodio 76 con pago -200.0\n",
      "Episodio 77 con pago -200.0\n",
      "Episodio 78 con pago -200.0\n",
      "Episodio 79 con pago -200.0\n",
      "Episodio 80 con pago -200.0\n",
      "Episodio 81 con pago -200.0\n",
      "Episodio 82 con pago -200.0\n",
      "Episodio 83 con pago -200.0\n",
      "Episodio 84 con pago -200.0\n",
      "Episodio 85 con pago -200.0\n",
      "Episodio 86 con pago -200.0\n",
      "Episodio 87 con pago -200.0\n",
      "Episodio 88 con pago -200.0\n",
      "Episodio 89 con pago -200.0\n",
      "Episodio 90 con pago -200.0\n",
      "Episodio 91 con pago -200.0\n",
      "Episodio 92 con pago -200.0\n",
      "Episodio 93 con pago -200.0\n",
      "Episodio 94 con pago -200.0\n",
      "Episodio 95 con pago -200.0\n",
      "Episodio 96 con pago -200.0\n",
      "Episodio 97 con pago -200.0\n",
      "Episodio 98 con pago -200.0\n",
      "Episodio 99 con pago -200.0\n",
      "Episodio 100 con pago -200.0\n",
      "Episodio 101 con pago -200.0\n",
      "Episodio 102 con pago -200.0\n",
      "Episodio 103 con pago -200.0\n",
      "Episodio 104 con pago -200.0\n",
      "Episodio 105 con pago -200.0\n",
      "Episodio 106 con pago -200.0\n",
      "Episodio 107 con pago -200.0\n",
      "Episodio 108 con pago -200.0\n",
      "Episodio 109 con pago -200.0\n",
      "Episodio 110 con pago -200.0\n",
      "Episodio 111 con pago -200.0\n",
      "Episodio 112 con pago -200.0\n",
      "Episodio 113 con pago -200.0\n",
      "Episodio 114 con pago -200.0\n",
      "Episodio 115 con pago -200.0\n",
      "Episodio 116 con pago -200.0\n",
      "Episodio 117 con pago -200.0\n",
      "Episodio 118 con pago -200.0\n",
      "Episodio 119 con pago -200.0\n",
      "Episodio 120 con pago -200.0\n",
      "Episodio 121 con pago -200.0\n",
      "Episodio 122 con pago -200.0\n",
      "Episodio 123 con pago -200.0\n",
      "Episodio 124 con pago -200.0\n",
      "Episodio 125 con pago -200.0\n",
      "Episodio 126 con pago -200.0\n",
      "Episodio 127 con pago -200.0\n",
      "Episodio 128 con pago -200.0\n",
      "Episodio 129 con pago -200.0\n",
      "Episodio 130 con pago -200.0\n",
      "Episodio 131 con pago -200.0\n",
      "Episodio 132 con pago -200.0\n",
      "Episodio 133 con pago -200.0\n",
      "Episodio 134 con pago -200.0\n",
      "Episodio 135 con pago -200.0\n",
      "Episodio 136 con pago -200.0\n",
      "Episodio 137 con pago -200.0\n",
      "Episodio 138 con pago -200.0\n",
      "Episodio 139 con pago -200.0\n",
      "Episodio 140 con pago -200.0\n",
      "Episodio 141 con pago -200.0\n",
      "Episodio 142 con pago -200.0\n",
      "Episodio 143 con pago -200.0\n",
      "Episodio 144 con pago -200.0\n",
      "Episodio 145 con pago -200.0\n",
      "Episodio 146 con pago -200.0\n",
      "Episodio 147 con pago -200.0\n",
      "Episodio 148 con pago -200.0\n",
      "Episodio 149 con pago -200.0\n",
      "Episodio 150 con pago -200.0\n",
      "Episodio 151 con pago -200.0\n",
      "Episodio 152 con pago -200.0\n",
      "Episodio 153 con pago -200.0\n",
      "Episodio 154 con pago -200.0\n",
      "Episodio 155 con pago -200.0\n",
      "Episodio 156 con pago -200.0\n",
      "Episodio 157 con pago -200.0\n",
      "Episodio 158 con pago -200.0\n",
      "Episodio 159 con pago -200.0\n",
      "Episodio 160 con pago -200.0\n",
      "Episodio 161 con pago -200.0\n",
      "Episodio 162 con pago -200.0\n",
      "Episodio 163 con pago -200.0\n",
      "Episodio 164 con pago -200.0\n",
      "Episodio 165 con pago -200.0\n",
      "Episodio 166 con pago -200.0\n",
      "Episodio 167 con pago -200.0\n",
      "Episodio 168 con pago -200.0\n",
      "Episodio 169 con pago -200.0\n",
      "Episodio 170 con pago -200.0\n",
      "Episodio 171 con pago -200.0\n",
      "Episodio 172 con pago -200.0\n",
      "Episodio 173 con pago -200.0\n",
      "Episodio 174 con pago -200.0\n",
      "Episodio 175 con pago -200.0\n",
      "Episodio 176 con pago -200.0\n",
      "Episodio 177 con pago -200.0\n",
      "Episodio 178 con pago -200.0\n",
      "Episodio 179 con pago -200.0\n",
      "Episodio 180 con pago -200.0\n",
      "Episodio 181 con pago -200.0\n",
      "Episodio 182 con pago -200.0\n",
      "Episodio 183 con pago -200.0\n",
      "Episodio 184 con pago -200.0\n",
      "Episodio 185 con pago -200.0\n",
      "Episodio 186 con pago -200.0\n",
      "Episodio 187 con pago -200.0\n",
      "Episodio 188 con pago -200.0\n",
      "Episodio 189 con pago -200.0\n",
      "Episodio 190 con pago -200.0\n",
      "Episodio 191 con pago -200.0\n",
      "Episodio 192 con pago -200.0\n",
      "Episodio 193 con pago -200.0\n",
      "Episodio 194 con pago -200.0\n",
      "Episodio 195 con pago -200.0\n",
      "Episodio 196 con pago -200.0\n",
      "Episodio 197 con pago -200.0\n",
      "Episodio 198 con pago -200.0\n",
      "Episodio 199 con pago -200.0\n",
      "Episodio 200 con pago -200.0\n",
      "Episodio 201 con pago -200.0\n",
      "Episodio 202 con pago -200.0\n",
      "Episodio 203 con pago -200.0\n",
      "Episodio 204 con pago -200.0\n",
      "Episodio 205 con pago -200.0\n",
      "Episodio 206 con pago -200.0\n",
      "Episodio 207 con pago -200.0\n",
      "Episodio 208 con pago -200.0\n",
      "Episodio 209 con pago -200.0\n",
      "Episodio 210 con pago -200.0\n",
      "Episodio 211 con pago -200.0\n",
      "Episodio 212 con pago -200.0\n",
      "Episodio 213 con pago -200.0\n",
      "Episodio 214 con pago -200.0\n",
      "Episodio 215 con pago -200.0\n",
      "Episodio 216 con pago -200.0\n",
      "Episodio 217 con pago -200.0\n",
      "Episodio 218 con pago -200.0\n",
      "Episodio 219 con pago -200.0\n",
      "Episodio 220 con pago -200.0\n",
      "Episodio 221 con pago -200.0\n",
      "Episodio 222 con pago -200.0\n",
      "Episodio 223 con pago -200.0\n",
      "Episodio 224 con pago -200.0\n",
      "Episodio 225 con pago -200.0\n",
      "Episodio 226 con pago -200.0\n",
      "Episodio 227 con pago -200.0\n",
      "Episodio 228 con pago -200.0\n",
      "Episodio 229 con pago -200.0\n",
      "Episodio 230 con pago -200.0\n",
      "Episodio 231 con pago -200.0\n",
      "Episodio 232 con pago -200.0\n",
      "Episodio 233 con pago -200.0\n",
      "Episodio 234 con pago -200.0\n",
      "Episodio 235 con pago -200.0\n",
      "Episodio 236 con pago -200.0\n",
      "Episodio 237 con pago -200.0\n",
      "Episodio 238 con pago -200.0\n",
      "Episodio 239 con pago -200.0\n",
      "Episodio 240 con pago -200.0\n",
      "Episodio 241 con pago -200.0\n",
      "Episodio 242 con pago -200.0\n",
      "Episodio 243 con pago -200.0\n",
      "Episodio 244 con pago -200.0\n",
      "Episodio 245 con pago -200.0\n",
      "Episodio 246 con pago -200.0\n",
      "Episodio 247 con pago -200.0\n",
      "Episodio 248 con pago -200.0\n",
      "Episodio 249 con pago -200.0\n",
      "Episodio 250 con pago -200.0\n",
      "Episodio 251 con pago -200.0\n",
      "Episodio 252 con pago -200.0\n",
      "Episodio 253 con pago -200.0\n",
      "Episodio 254 con pago -200.0\n",
      "Episodio 255 con pago -200.0\n",
      "Episodio 256 con pago -200.0\n",
      "Episodio 257 con pago -200.0\n",
      "Episodio 258 con pago -200.0\n",
      "Episodio 259 con pago -200.0\n",
      "Episodio 260 con pago -200.0\n",
      "Episodio 261 con pago -162.0\n",
      "Episodio 262 con pago -200.0\n",
      "Episodio 263 con pago -200.0\n",
      "Episodio 264 con pago -200.0\n",
      "Episodio 265 con pago -200.0\n",
      "Episodio 266 con pago -200.0\n",
      "Episodio 267 con pago -200.0\n",
      "Episodio 268 con pago -200.0\n",
      "Episodio 269 con pago -200.0\n",
      "Episodio 270 con pago -200.0\n",
      "Episodio 271 con pago -200.0\n",
      "Episodio 272 con pago -200.0\n",
      "Episodio 273 con pago -200.0\n",
      "Episodio 274 con pago -200.0\n",
      "Episodio 275 con pago -200.0\n",
      "Episodio 276 con pago -200.0\n",
      "Episodio 277 con pago -200.0\n",
      "Episodio 278 con pago -200.0\n",
      "Episodio 279 con pago -200.0\n",
      "Episodio 280 con pago -200.0\n",
      "Episodio 281 con pago -200.0\n",
      "Episodio 282 con pago -200.0\n",
      "Episodio 283 con pago -200.0\n",
      "Episodio 284 con pago -200.0\n",
      "Episodio 285 con pago -200.0\n",
      "Episodio 286 con pago -200.0\n",
      "Episodio 287 con pago -200.0\n",
      "Episodio 288 con pago -200.0\n",
      "Episodio 289 con pago -200.0\n",
      "Episodio 290 con pago -200.0\n",
      "Episodio 291 con pago -200.0\n",
      "Episodio 292 con pago -200.0\n",
      "Episodio 293 con pago -200.0\n",
      "Episodio 294 con pago -200.0\n",
      "Episodio 295 con pago -177.0\n",
      "Episodio 296 con pago -200.0\n",
      "Episodio 297 con pago -200.0\n",
      "Episodio 298 con pago -200.0\n",
      "Episodio 299 con pago -126.0\n",
      "Episodio 300 con pago -200.0\n",
      "Episodio 301 con pago -200.0\n",
      "Episodio 302 con pago -200.0\n",
      "Episodio 303 con pago -200.0\n",
      "Episodio 304 con pago -200.0\n",
      "Episodio 305 con pago -200.0\n",
      "Episodio 306 con pago -200.0\n",
      "Episodio 307 con pago -200.0\n",
      "Episodio 308 con pago -200.0\n",
      "Episodio 309 con pago -200.0\n",
      "Episodio 310 con pago -200.0\n",
      "Episodio 311 con pago -200.0\n",
      "Episodio 312 con pago -200.0\n",
      "Episodio 313 con pago -200.0\n",
      "Episodio 314 con pago -200.0\n",
      "Episodio 315 con pago -200.0\n",
      "Episodio 316 con pago -200.0\n",
      "Episodio 317 con pago -200.0\n",
      "Episodio 318 con pago -200.0\n",
      "Episodio 319 con pago -200.0\n",
      "Episodio 320 con pago -200.0\n",
      "Episodio 321 con pago -200.0\n",
      "Episodio 322 con pago -200.0\n",
      "Episodio 323 con pago -200.0\n",
      "Episodio 324 con pago -200.0\n",
      "Episodio 325 con pago -200.0\n",
      "Episodio 326 con pago -200.0\n",
      "Episodio 327 con pago -200.0\n",
      "Episodio 328 con pago -200.0\n",
      "Episodio 329 con pago -200.0\n",
      "Episodio 330 con pago -200.0\n",
      "Episodio 331 con pago -200.0\n",
      "Episodio 332 con pago -200.0\n",
      "Episodio 333 con pago -200.0\n",
      "Episodio 334 con pago -200.0\n",
      "Episodio 335 con pago -200.0\n",
      "Episodio 336 con pago -200.0\n",
      "Episodio 337 con pago -200.0\n",
      "Episodio 338 con pago -200.0\n",
      "Episodio 339 con pago -200.0\n",
      "Episodio 340 con pago -200.0\n",
      "Episodio 341 con pago -200.0\n",
      "Episodio 342 con pago -200.0\n",
      "Episodio 343 con pago -200.0\n",
      "Episodio 344 con pago -200.0\n",
      "Episodio 345 con pago -200.0\n",
      "Episodio 346 con pago -200.0\n",
      "Episodio 347 con pago -200.0\n",
      "Episodio 348 con pago -200.0\n",
      "Episodio 349 con pago -200.0\n",
      "Episodio 350 con pago -200.0\n",
      "Episodio 351 con pago -200.0\n",
      "Episodio 352 con pago -200.0\n",
      "Episodio 353 con pago -200.0\n",
      "Episodio 354 con pago -200.0\n",
      "Episodio 355 con pago -200.0\n",
      "Episodio 356 con pago -200.0\n",
      "Episodio 357 con pago -200.0\n",
      "Episodio 358 con pago -200.0\n",
      "Episodio 359 con pago -200.0\n",
      "Episodio 360 con pago -200.0\n",
      "Episodio 361 con pago -200.0\n",
      "Episodio 362 con pago -200.0\n",
      "Episodio 363 con pago -200.0\n",
      "Episodio 364 con pago -200.0\n",
      "Episodio 365 con pago -200.0\n",
      "Episodio 366 con pago -200.0\n",
      "Episodio 367 con pago -200.0\n",
      "Episodio 368 con pago -200.0\n",
      "Episodio 369 con pago -200.0\n",
      "Episodio 370 con pago -200.0\n",
      "Episodio 371 con pago -200.0\n",
      "Episodio 372 con pago -200.0\n",
      "Episodio 373 con pago -200.0\n",
      "Episodio 374 con pago -200.0\n",
      "Episodio 375 con pago -200.0\n",
      "Episodio 376 con pago -163.0\n",
      "Episodio 377 con pago -200.0\n",
      "Episodio 378 con pago -200.0\n",
      "Episodio 379 con pago -200.0\n",
      "Episodio 380 con pago -200.0\n",
      "Episodio 381 con pago -200.0\n",
      "Episodio 382 con pago -196.0\n",
      "Episodio 383 con pago -200.0\n",
      "Episodio 384 con pago -200.0\n",
      "Episodio 385 con pago -200.0\n",
      "Episodio 386 con pago -200.0\n",
      "Episodio 387 con pago -200.0\n",
      "Episodio 388 con pago -180.0\n",
      "Episodio 389 con pago -200.0\n",
      "Episodio 390 con pago -200.0\n",
      "Episodio 391 con pago -200.0\n",
      "Episodio 392 con pago -200.0\n",
      "Episodio 393 con pago -200.0\n",
      "Episodio 394 con pago -200.0\n",
      "Episodio 395 con pago -200.0\n",
      "Episodio 396 con pago -200.0\n",
      "Episodio 397 con pago -200.0\n",
      "Episodio 398 con pago -200.0\n",
      "Episodio 399 con pago -157.0\n",
      "Episodio 400 con pago -200.0\n",
      "Episodio 401 con pago -200.0\n",
      "Episodio 402 con pago -200.0\n",
      "Episodio 403 con pago -200.0\n",
      "Episodio 404 con pago -200.0\n",
      "Episodio 405 con pago -200.0\n",
      "Episodio 406 con pago -200.0\n",
      "Episodio 407 con pago -181.0\n",
      "Episodio 408 con pago -198.0\n",
      "Episodio 409 con pago -200.0\n",
      "Episodio 410 con pago -200.0\n",
      "Episodio 411 con pago -184.0\n",
      "Episodio 412 con pago -200.0\n",
      "Episodio 413 con pago -200.0\n",
      "Episodio 414 con pago -200.0\n",
      "Episodio 415 con pago -200.0\n",
      "Episodio 416 con pago -173.0\n",
      "Episodio 417 con pago -200.0\n",
      "Episodio 418 con pago -200.0\n",
      "Episodio 419 con pago -200.0\n",
      "Episodio 420 con pago -196.0\n",
      "Episodio 421 con pago -200.0\n",
      "Episodio 422 con pago -200.0\n",
      "Episodio 423 con pago -200.0\n",
      "Episodio 424 con pago -191.0\n",
      "Episodio 425 con pago -200.0\n",
      "Episodio 426 con pago -200.0\n",
      "Episodio 427 con pago -200.0\n",
      "Episodio 428 con pago -200.0\n",
      "Episodio 429 con pago -200.0\n",
      "Episodio 430 con pago -200.0\n",
      "Episodio 431 con pago -200.0\n",
      "Episodio 432 con pago -200.0\n",
      "Episodio 433 con pago -200.0\n",
      "Episodio 434 con pago -200.0\n",
      "Episodio 435 con pago -200.0\n",
      "Episodio 436 con pago -200.0\n",
      "Episodio 437 con pago -200.0\n",
      "Episodio 438 con pago -200.0\n",
      "Episodio 439 con pago -200.0\n",
      "Episodio 440 con pago -200.0\n",
      "Episodio 441 con pago -200.0\n",
      "Episodio 442 con pago -200.0\n",
      "Episodio 443 con pago -200.0\n",
      "Episodio 444 con pago -200.0\n",
      "Episodio 445 con pago -200.0\n",
      "Episodio 446 con pago -200.0\n",
      "Episodio 447 con pago -200.0\n",
      "Episodio 448 con pago -200.0\n",
      "Episodio 449 con pago -200.0\n",
      "Episodio 450 con pago -200.0\n",
      "Episodio 451 con pago -200.0\n",
      "Episodio 452 con pago -200.0\n",
      "Episodio 453 con pago -200.0\n",
      "Episodio 454 con pago -200.0\n",
      "Episodio 455 con pago -200.0\n",
      "Episodio 456 con pago -200.0\n",
      "Episodio 457 con pago -148.0\n",
      "Episodio 458 con pago -200.0\n",
      "Episodio 459 con pago -156.0\n",
      "Episodio 460 con pago -200.0\n",
      "Episodio 461 con pago -200.0\n",
      "Episodio 462 con pago -200.0\n",
      "Episodio 463 con pago -200.0\n",
      "Episodio 464 con pago -200.0\n",
      "Episodio 465 con pago -200.0\n",
      "Episodio 466 con pago -200.0\n",
      "Episodio 467 con pago -200.0\n",
      "Episodio 468 con pago -200.0\n",
      "Episodio 469 con pago -200.0\n",
      "Episodio 470 con pago -162.0\n",
      "Episodio 471 con pago -164.0\n",
      "Episodio 472 con pago -200.0\n",
      "Episodio 473 con pago -200.0\n",
      "Episodio 474 con pago -200.0\n",
      "Episodio 475 con pago -200.0\n",
      "Episodio 476 con pago -200.0\n",
      "Episodio 477 con pago -200.0\n",
      "Episodio 478 con pago -200.0\n",
      "Episodio 479 con pago -200.0\n",
      "Episodio 480 con pago -200.0\n",
      "Episodio 481 con pago -200.0\n",
      "Episodio 482 con pago -200.0\n",
      "Episodio 483 con pago -200.0\n",
      "Episodio 484 con pago -200.0\n",
      "Episodio 485 con pago -200.0\n",
      "Episodio 486 con pago -200.0\n",
      "Episodio 487 con pago -200.0\n",
      "Episodio 488 con pago -200.0\n",
      "Episodio 489 con pago -200.0\n",
      "Episodio 490 con pago -200.0\n",
      "Episodio 491 con pago -200.0\n",
      "Episodio 492 con pago -200.0\n",
      "Episodio 493 con pago -200.0\n",
      "Episodio 494 con pago -200.0\n",
      "Episodio 495 con pago -200.0\n",
      "Episodio 496 con pago -200.0\n",
      "Episodio 497 con pago -200.0\n",
      "Episodio 498 con pago -200.0\n",
      "Episodio 499 con pago -200.0\n",
      "Episodio 500 con pago -200.0\n",
      "Episodio 501 con pago -200.0\n",
      "Episodio 502 con pago -200.0\n",
      "Episodio 503 con pago -200.0\n",
      "Episodio 504 con pago -200.0\n",
      "Episodio 505 con pago -200.0\n",
      "Episodio 506 con pago -200.0\n",
      "Episodio 507 con pago -200.0\n",
      "Episodio 508 con pago -200.0\n",
      "Episodio 509 con pago -200.0\n",
      "Episodio 510 con pago -200.0\n",
      "Episodio 511 con pago -200.0\n",
      "Episodio 512 con pago -200.0\n",
      "Episodio 513 con pago -200.0\n",
      "Episodio 514 con pago -172.0\n",
      "Episodio 515 con pago -200.0\n",
      "Episodio 516 con pago -200.0\n",
      "Episodio 517 con pago -200.0\n",
      "Episodio 518 con pago -200.0\n",
      "Episodio 519 con pago -200.0\n",
      "Episodio 520 con pago -200.0\n",
      "Episodio 521 con pago -200.0\n",
      "Episodio 522 con pago -200.0\n",
      "Episodio 523 con pago -200.0\n",
      "Episodio 524 con pago -200.0\n",
      "Episodio 525 con pago -200.0\n",
      "Episodio 526 con pago -200.0\n",
      "Episodio 527 con pago -200.0\n",
      "Episodio 528 con pago -200.0\n",
      "Episodio 529 con pago -200.0\n",
      "Episodio 530 con pago -200.0\n",
      "Episodio 531 con pago -200.0\n",
      "Episodio 532 con pago -200.0\n",
      "Episodio 533 con pago -200.0\n",
      "Episodio 534 con pago -200.0\n",
      "Episodio 535 con pago -200.0\n",
      "Episodio 536 con pago -200.0\n",
      "Episodio 537 con pago -200.0\n",
      "Episodio 538 con pago -200.0\n",
      "Episodio 539 con pago -197.0\n",
      "Episodio 540 con pago -200.0\n",
      "Episodio 541 con pago -200.0\n",
      "Episodio 542 con pago -200.0\n",
      "Episodio 543 con pago -200.0\n",
      "Episodio 544 con pago -200.0\n",
      "Episodio 545 con pago -200.0\n",
      "Episodio 546 con pago -158.0\n",
      "Episodio 547 con pago -200.0\n",
      "Episodio 548 con pago -200.0\n",
      "Episodio 549 con pago -200.0\n",
      "Episodio 550 con pago -200.0\n",
      "Episodio 551 con pago -200.0\n",
      "Episodio 552 con pago -200.0\n",
      "Episodio 553 con pago -200.0\n",
      "Episodio 554 con pago -200.0\n",
      "Episodio 555 con pago -200.0\n",
      "Episodio 556 con pago -200.0\n",
      "Episodio 557 con pago -200.0\n",
      "Episodio 558 con pago -200.0\n",
      "Episodio 559 con pago -200.0\n",
      "Episodio 560 con pago -200.0\n",
      "Episodio 561 con pago -200.0\n",
      "Episodio 562 con pago -200.0\n",
      "Episodio 563 con pago -200.0\n",
      "Episodio 564 con pago -200.0\n",
      "Episodio 565 con pago -200.0\n",
      "Episodio 566 con pago -200.0\n",
      "Episodio 567 con pago -200.0\n",
      "Episodio 568 con pago -200.0\n",
      "Episodio 569 con pago -200.0\n",
      "Episodio 570 con pago -200.0\n",
      "Episodio 571 con pago -200.0\n",
      "Episodio 572 con pago -200.0\n",
      "Episodio 573 con pago -200.0\n",
      "Episodio 574 con pago -200.0\n",
      "Episodio 575 con pago -200.0\n",
      "Episodio 576 con pago -200.0\n",
      "Episodio 577 con pago -200.0\n",
      "Episodio 578 con pago -200.0\n",
      "Episodio 579 con pago -200.0\n",
      "Episodio 580 con pago -200.0\n",
      "Episodio 581 con pago -200.0\n",
      "Episodio 582 con pago -200.0\n",
      "Episodio 583 con pago -200.0\n",
      "Episodio 584 con pago -200.0\n",
      "Episodio 585 con pago -200.0\n",
      "Episodio 586 con pago -200.0\n",
      "Episodio 587 con pago -200.0\n",
      "Episodio 588 con pago -200.0\n",
      "Episodio 589 con pago -200.0\n",
      "Episodio 590 con pago -176.0\n",
      "Episodio 591 con pago -200.0\n",
      "Episodio 592 con pago -200.0\n",
      "Episodio 593 con pago -200.0\n",
      "Episodio 594 con pago -200.0\n",
      "Episodio 595 con pago -169.0\n",
      "Episodio 596 con pago -200.0\n",
      "Episodio 597 con pago -200.0\n",
      "Episodio 598 con pago -200.0\n",
      "Episodio 599 con pago -200.0\n",
      "Episodio 600 con pago -200.0\n",
      "Episodio 601 con pago -200.0\n",
      "Episodio 602 con pago -200.0\n",
      "Episodio 603 con pago -200.0\n",
      "Episodio 604 con pago -200.0\n",
      "Episodio 605 con pago -200.0\n",
      "Episodio 606 con pago -200.0\n",
      "Episodio 607 con pago -200.0\n",
      "Episodio 608 con pago -200.0\n",
      "Episodio 609 con pago -200.0\n",
      "Episodio 610 con pago -200.0\n",
      "Episodio 611 con pago -200.0\n",
      "Episodio 612 con pago -200.0\n",
      "Episodio 613 con pago -200.0\n",
      "Episodio 614 con pago -200.0\n",
      "Episodio 615 con pago -200.0\n",
      "Episodio 616 con pago -198.0\n",
      "Episodio 617 con pago -200.0\n",
      "Episodio 618 con pago -200.0\n",
      "Episodio 619 con pago -200.0\n",
      "Episodio 620 con pago -195.0\n",
      "Episodio 621 con pago -200.0\n",
      "Episodio 622 con pago -200.0\n",
      "Episodio 623 con pago -200.0\n",
      "Episodio 624 con pago -200.0\n",
      "Episodio 625 con pago -200.0\n",
      "Episodio 626 con pago -200.0\n",
      "Episodio 627 con pago -200.0\n",
      "Episodio 628 con pago -145.0\n",
      "Episodio 629 con pago -200.0\n",
      "Episodio 630 con pago -200.0\n",
      "Episodio 631 con pago -200.0\n",
      "Episodio 632 con pago -200.0\n",
      "Episodio 633 con pago -200.0\n",
      "Episodio 634 con pago -200.0\n",
      "Episodio 635 con pago -200.0\n",
      "Episodio 636 con pago -200.0\n",
      "Episodio 637 con pago -165.0\n",
      "Episodio 638 con pago -200.0\n",
      "Episodio 639 con pago -172.0\n",
      "Episodio 640 con pago -163.0\n",
      "Episodio 641 con pago -171.0\n",
      "Episodio 642 con pago -166.0\n",
      "Episodio 643 con pago -200.0\n",
      "Episodio 644 con pago -163.0\n",
      "Episodio 645 con pago -200.0\n",
      "Episodio 646 con pago -163.0\n",
      "Episodio 647 con pago -164.0\n",
      "Episodio 648 con pago -200.0\n",
      "Episodio 649 con pago -200.0\n",
      "Episodio 650 con pago -200.0\n",
      "Episodio 651 con pago -200.0\n",
      "Episodio 652 con pago -200.0\n",
      "Episodio 653 con pago -200.0\n",
      "Episodio 654 con pago -200.0\n",
      "Episodio 655 con pago -159.0\n",
      "Episodio 656 con pago -165.0\n",
      "Episodio 657 con pago -152.0\n",
      "Episodio 658 con pago -200.0\n",
      "Episodio 659 con pago -200.0\n",
      "Episodio 660 con pago -200.0\n",
      "Episodio 661 con pago -200.0\n",
      "Episodio 662 con pago -200.0\n",
      "Episodio 663 con pago -200.0\n",
      "Episodio 664 con pago -200.0\n",
      "Episodio 665 con pago -180.0\n",
      "Episodio 666 con pago -200.0\n",
      "Episodio 667 con pago -200.0\n",
      "Episodio 668 con pago -200.0\n",
      "Episodio 669 con pago -200.0\n",
      "Episodio 670 con pago -200.0\n",
      "Episodio 671 con pago -200.0\n",
      "Episodio 672 con pago -200.0\n",
      "Episodio 673 con pago -200.0\n",
      "Episodio 674 con pago -200.0\n",
      "Episodio 675 con pago -200.0\n",
      "Episodio 676 con pago -200.0\n",
      "Episodio 677 con pago -200.0\n",
      "Episodio 678 con pago -200.0\n",
      "Episodio 679 con pago -200.0\n",
      "Episodio 680 con pago -200.0\n",
      "Episodio 681 con pago -200.0\n",
      "Episodio 682 con pago -200.0\n",
      "Episodio 683 con pago -200.0\n",
      "Episodio 684 con pago -200.0\n",
      "Episodio 685 con pago -200.0\n",
      "Episodio 686 con pago -200.0\n",
      "Episodio 687 con pago -200.0\n",
      "Episodio 688 con pago -200.0\n",
      "Episodio 689 con pago -200.0\n",
      "Episodio 690 con pago -200.0\n",
      "Episodio 691 con pago -200.0\n",
      "Episodio 692 con pago -200.0\n",
      "Episodio 693 con pago -200.0\n",
      "Episodio 694 con pago -200.0\n",
      "Episodio 695 con pago -200.0\n",
      "Episodio 696 con pago -200.0\n",
      "Episodio 697 con pago -200.0\n",
      "Episodio 698 con pago -200.0\n",
      "Episodio 699 con pago -200.0\n",
      "Episodio 700 con pago -200.0\n",
      "Episodio 701 con pago -200.0\n",
      "Episodio 702 con pago -157.0\n",
      "Episodio 703 con pago -200.0\n",
      "Episodio 704 con pago -200.0\n",
      "Episodio 705 con pago -200.0\n",
      "Episodio 706 con pago -200.0\n",
      "Episodio 707 con pago -200.0\n",
      "Episodio 708 con pago -200.0\n",
      "Episodio 709 con pago -200.0\n",
      "Episodio 710 con pago -200.0\n",
      "Episodio 711 con pago -200.0\n",
      "Episodio 712 con pago -200.0\n",
      "Episodio 713 con pago -200.0\n",
      "Episodio 714 con pago -200.0\n",
      "Episodio 715 con pago -200.0\n",
      "Episodio 716 con pago -200.0\n",
      "Episodio 717 con pago -200.0\n",
      "Episodio 718 con pago -200.0\n",
      "Episodio 719 con pago -200.0\n",
      "Episodio 720 con pago -200.0\n",
      "Episodio 721 con pago -200.0\n",
      "Episodio 722 con pago -200.0\n",
      "Episodio 723 con pago -200.0\n",
      "Episodio 724 con pago -200.0\n",
      "Episodio 725 con pago -200.0\n",
      "Episodio 726 con pago -200.0\n",
      "Episodio 727 con pago -200.0\n",
      "Episodio 728 con pago -200.0\n",
      "Episodio 729 con pago -200.0\n",
      "Episodio 730 con pago -200.0\n",
      "Episodio 731 con pago -200.0\n",
      "Episodio 732 con pago -200.0\n",
      "Episodio 733 con pago -200.0\n",
      "Episodio 734 con pago -200.0\n",
      "Episodio 735 con pago -200.0\n",
      "Episodio 736 con pago -188.0\n",
      "Episodio 737 con pago -200.0\n",
      "Episodio 738 con pago -200.0\n",
      "Episodio 739 con pago -193.0\n",
      "Episodio 740 con pago -200.0\n",
      "Episodio 741 con pago -164.0\n",
      "Episodio 742 con pago -200.0\n",
      "Episodio 743 con pago -200.0\n",
      "Episodio 744 con pago -200.0\n",
      "Episodio 745 con pago -200.0\n",
      "Episodio 746 con pago -200.0\n",
      "Episodio 747 con pago -200.0\n",
      "Episodio 748 con pago -153.0\n",
      "Episodio 749 con pago -166.0\n",
      "Episodio 750 con pago -200.0\n",
      "Episodio 751 con pago -200.0\n",
      "Episodio 752 con pago -200.0\n",
      "Episodio 753 con pago -200.0\n",
      "Episodio 754 con pago -200.0\n",
      "Episodio 755 con pago -166.0\n",
      "Episodio 756 con pago -166.0\n",
      "Episodio 757 con pago -172.0\n",
      "Episodio 758 con pago -165.0\n",
      "Episodio 759 con pago -200.0\n",
      "Episodio 760 con pago -200.0\n",
      "Episodio 761 con pago -200.0\n",
      "Episodio 762 con pago -175.0\n",
      "Episodio 763 con pago -200.0\n",
      "Episodio 764 con pago -200.0\n",
      "Episodio 765 con pago -200.0\n",
      "Episodio 766 con pago -200.0\n",
      "Episodio 767 con pago -200.0\n",
      "Episodio 768 con pago -200.0\n",
      "Episodio 769 con pago -200.0\n",
      "Episodio 770 con pago -200.0\n",
      "Episodio 771 con pago -200.0\n",
      "Episodio 772 con pago -200.0\n",
      "Episodio 773 con pago -200.0\n",
      "Episodio 774 con pago -174.0\n",
      "Episodio 775 con pago -200.0\n",
      "Episodio 776 con pago -200.0\n",
      "Episodio 777 con pago -200.0\n",
      "Episodio 778 con pago -200.0\n",
      "Episodio 779 con pago -200.0\n",
      "Episodio 780 con pago -200.0\n",
      "Episodio 781 con pago -200.0\n",
      "Episodio 782 con pago -200.0\n",
      "Episodio 783 con pago -175.0\n",
      "Episodio 784 con pago -200.0\n",
      "Episodio 785 con pago -200.0\n",
      "Episodio 786 con pago -127.0\n",
      "Episodio 787 con pago -200.0\n",
      "Episodio 788 con pago -200.0\n",
      "Episodio 789 con pago -200.0\n",
      "Episodio 790 con pago -200.0\n",
      "Episodio 791 con pago -200.0\n",
      "Episodio 792 con pago -200.0\n",
      "Episodio 793 con pago -200.0\n",
      "Episodio 794 con pago -200.0\n",
      "Episodio 795 con pago -200.0\n",
      "Episodio 796 con pago -200.0\n",
      "Episodio 797 con pago -200.0\n",
      "Episodio 798 con pago -200.0\n",
      "Episodio 799 con pago -200.0\n",
      "Episodio 800 con pago -200.0\n",
      "Episodio 801 con pago -167.0\n",
      "Episodio 802 con pago -200.0\n",
      "Episodio 803 con pago -200.0\n",
      "Episodio 804 con pago -200.0\n",
      "Episodio 805 con pago -183.0\n",
      "Episodio 806 con pago -200.0\n",
      "Episodio 807 con pago -200.0\n",
      "Episodio 808 con pago -200.0\n",
      "Episodio 809 con pago -200.0\n",
      "Episodio 810 con pago -200.0\n",
      "Episodio 811 con pago -200.0\n",
      "Episodio 812 con pago -200.0\n",
      "Episodio 813 con pago -200.0\n",
      "Episodio 814 con pago -195.0\n",
      "Episodio 815 con pago -200.0\n",
      "Episodio 816 con pago -200.0\n",
      "Episodio 817 con pago -200.0\n",
      "Episodio 818 con pago -200.0\n",
      "Episodio 819 con pago -200.0\n",
      "Episodio 820 con pago -200.0\n",
      "Episodio 821 con pago -200.0\n",
      "Episodio 822 con pago -200.0\n",
      "Episodio 823 con pago -133.0\n",
      "Episodio 824 con pago -200.0\n",
      "Episodio 825 con pago -200.0\n",
      "Episodio 826 con pago -200.0\n",
      "Episodio 827 con pago -200.0\n",
      "Episodio 828 con pago -200.0\n",
      "Episodio 829 con pago -200.0\n",
      "Episodio 830 con pago -200.0\n",
      "Episodio 831 con pago -200.0\n",
      "Episodio 832 con pago -200.0\n",
      "Episodio 833 con pago -200.0\n",
      "Episodio 834 con pago -200.0\n",
      "Episodio 835 con pago -200.0\n",
      "Episodio 836 con pago -200.0\n",
      "Episodio 837 con pago -200.0\n",
      "Episodio 838 con pago -200.0\n",
      "Episodio 839 con pago -160.0\n",
      "Episodio 840 con pago -200.0\n",
      "Episodio 841 con pago -200.0\n",
      "Episodio 842 con pago -200.0\n",
      "Episodio 843 con pago -200.0\n",
      "Episodio 844 con pago -200.0\n",
      "Episodio 845 con pago -200.0\n",
      "Episodio 846 con pago -174.0\n",
      "Episodio 847 con pago -200.0\n",
      "Episodio 848 con pago -162.0\n",
      "Episodio 849 con pago -200.0\n",
      "Episodio 850 con pago -200.0\n",
      "Episodio 851 con pago -200.0\n",
      "Episodio 852 con pago -200.0\n",
      "Episodio 853 con pago -200.0\n",
      "Episodio 854 con pago -200.0\n",
      "Episodio 855 con pago -200.0\n",
      "Episodio 856 con pago -200.0\n",
      "Episodio 857 con pago -149.0\n",
      "Episodio 858 con pago -125.0\n",
      "Episodio 859 con pago -200.0\n",
      "Episodio 860 con pago -135.0\n",
      "Episodio 861 con pago -143.0\n",
      "Episodio 862 con pago -149.0\n",
      "Episodio 863 con pago -200.0\n",
      "Episodio 864 con pago -200.0\n",
      "Episodio 865 con pago -200.0\n",
      "Episodio 866 con pago -200.0\n",
      "Episodio 867 con pago -200.0\n",
      "Episodio 868 con pago -200.0\n",
      "Episodio 869 con pago -200.0\n",
      "Episodio 870 con pago -200.0\n",
      "Episodio 871 con pago -200.0\n",
      "Episodio 872 con pago -200.0\n",
      "Episodio 873 con pago -200.0\n",
      "Episodio 874 con pago -200.0\n",
      "Episodio 875 con pago -200.0\n",
      "Episodio 876 con pago -200.0\n",
      "Episodio 877 con pago -200.0\n",
      "Episodio 878 con pago -200.0\n",
      "Episodio 879 con pago -200.0\n",
      "Episodio 880 con pago -200.0\n",
      "Episodio 881 con pago -200.0\n",
      "Episodio 882 con pago -200.0\n",
      "Episodio 883 con pago -200.0\n",
      "Episodio 884 con pago -200.0\n",
      "Episodio 885 con pago -200.0\n",
      "Episodio 886 con pago -200.0\n",
      "Episodio 887 con pago -200.0\n",
      "Episodio 888 con pago -200.0\n",
      "Episodio 889 con pago -200.0\n",
      "Episodio 890 con pago -160.0\n",
      "Episodio 891 con pago -200.0\n",
      "Episodio 892 con pago -200.0\n",
      "Episodio 893 con pago -166.0\n",
      "Episodio 894 con pago -162.0\n",
      "Episodio 895 con pago -167.0\n",
      "Episodio 896 con pago -200.0\n",
      "Episodio 897 con pago -200.0\n",
      "Episodio 898 con pago -200.0\n",
      "Episodio 899 con pago -200.0\n",
      "Episodio 900 con pago -200.0\n",
      "Episodio 901 con pago -200.0\n",
      "Episodio 902 con pago -200.0\n",
      "Episodio 903 con pago -200.0\n",
      "Episodio 904 con pago -200.0\n",
      "Episodio 905 con pago -200.0\n",
      "Episodio 906 con pago -186.0\n",
      "Episodio 907 con pago -172.0\n",
      "Episodio 908 con pago -200.0\n",
      "Episodio 909 con pago -200.0\n",
      "Episodio 910 con pago -200.0\n",
      "Episodio 911 con pago -200.0\n",
      "Episodio 912 con pago -167.0\n",
      "Episodio 913 con pago -164.0\n",
      "Episodio 914 con pago -200.0\n",
      "Episodio 915 con pago -200.0\n",
      "Episodio 916 con pago -165.0\n",
      "Episodio 917 con pago -200.0\n",
      "Episodio 918 con pago -200.0\n",
      "Episodio 919 con pago -200.0\n",
      "Episodio 920 con pago -183.0\n",
      "Episodio 921 con pago -175.0\n",
      "Episodio 922 con pago -200.0\n",
      "Episodio 923 con pago -200.0\n",
      "Episodio 924 con pago -200.0\n",
      "Episodio 925 con pago -200.0\n",
      "Episodio 926 con pago -200.0\n",
      "Episodio 927 con pago -200.0\n",
      "Episodio 928 con pago -176.0\n",
      "Episodio 929 con pago -200.0\n",
      "Episodio 930 con pago -183.0\n",
      "Episodio 931 con pago -186.0\n",
      "Episodio 932 con pago -178.0\n",
      "Episodio 933 con pago -166.0\n",
      "Episodio 934 con pago -200.0\n",
      "Episodio 935 con pago -200.0\n",
      "Episodio 936 con pago -200.0\n",
      "Episodio 937 con pago -200.0\n",
      "Episodio 938 con pago -200.0\n",
      "Episodio 939 con pago -200.0\n",
      "Episodio 940 con pago -200.0\n",
      "Episodio 941 con pago -200.0\n",
      "Episodio 942 con pago -169.0\n",
      "Episodio 943 con pago -200.0\n",
      "Episodio 944 con pago -200.0\n",
      "Episodio 945 con pago -200.0\n",
      "Episodio 946 con pago -200.0\n",
      "Episodio 947 con pago -200.0\n",
      "Episodio 948 con pago -200.0\n",
      "Episodio 949 con pago -200.0\n",
      "Episodio 950 con pago -199.0\n",
      "Episodio 951 con pago -200.0\n",
      "Episodio 952 con pago -200.0\n",
      "Episodio 953 con pago -200.0\n",
      "Episodio 954 con pago -200.0\n",
      "Episodio 955 con pago -200.0\n",
      "Episodio 956 con pago -200.0\n",
      "Episodio 957 con pago -162.0\n",
      "Episodio 958 con pago -200.0\n",
      "Episodio 959 con pago -200.0\n",
      "Episodio 960 con pago -200.0\n",
      "Episodio 961 con pago -200.0\n",
      "Episodio 962 con pago -200.0\n",
      "Episodio 963 con pago -200.0\n",
      "Episodio 964 con pago -195.0\n",
      "Episodio 965 con pago -200.0\n",
      "Episodio 966 con pago -200.0\n",
      "Episodio 967 con pago -141.0\n",
      "Episodio 968 con pago -147.0\n",
      "Episodio 969 con pago -145.0\n",
      "Episodio 970 con pago -200.0\n",
      "Episodio 971 con pago -150.0\n",
      "Episodio 972 con pago -200.0\n",
      "Episodio 973 con pago -200.0\n",
      "Episodio 974 con pago -151.0\n",
      "Episodio 975 con pago -200.0\n",
      "Episodio 976 con pago -200.0\n",
      "Episodio 977 con pago -200.0\n",
      "Episodio 978 con pago -200.0\n",
      "Episodio 979 con pago -200.0\n",
      "Episodio 980 con pago -200.0\n",
      "Episodio 981 con pago -200.0\n",
      "Episodio 982 con pago -190.0\n",
      "Episodio 983 con pago -192.0\n",
      "Episodio 984 con pago -200.0\n",
      "Episodio 985 con pago -200.0\n",
      "Episodio 986 con pago -200.0\n",
      "Episodio 987 con pago -200.0\n",
      "Episodio 988 con pago -200.0\n",
      "Episodio 989 con pago -200.0\n",
      "Episodio 990 con pago -200.0\n",
      "Episodio 991 con pago -200.0\n",
      "Episodio 992 con pago -163.0\n",
      "Episodio 993 con pago -159.0\n",
      "Episodio 994 con pago -200.0\n",
      "Episodio 995 con pago -200.0\n",
      "Episodio 996 con pago -200.0\n",
      "Episodio 997 con pago -200.0\n",
      "Episodio 998 con pago -200.0\n",
      "Episodio 999 con pago -200.0\n",
      "Episodio 1000 con pago -200.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dict{Any,Any}(Pair{Any,Any}((Float32[-0.24,-0.05],0),-23.8864),Pair{Any,Any}((Float32[-0.48,-0.07],0),-0.627288),Pair{Any,Any}((Float32[0.0,0.03],2),-23.3714),Pair{Any,Any}((Float32[-0.96,0.03],0),-34.9363),Pair{Any,Any}((Float32[-1.08,-0.01],0),-36.6051),Pair{Any,Any}((Float32[-0.96,0.03],2),-34.9797),Pair{Any,Any}((Float32[-0.36,0.05],1),-26.7599),Pair{Any,Any}((Float32[0.0,0.05],2),-15.8192),Pair{Any,Any}((Float32[-0.24,-0.03],1),-38.2981),Pair{Any,Any}((Float32[0.24,0.05],1),-1.28637)…),Any[-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0  …  -200.0,-163.0,-159.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0,-200.0],Any[200,200,200,200,200,200,200,200,200,200  …  200,163,159,200,200,200,200,200,200,200])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, reward_history, steps_history = learn_episodes_with_qlearning(\n",
    "    1000, mountain_car, Dict(), \n",
    "    preprocess_state = preprocess,\n",
    "    learning_rate = 0.05,\n",
    "    exploration_rate = 0.25,\n",
    "    exploration_decay = 1 - log(25) / 1000, # will reduce to 0.01 at the end of training\n",
    "    render = true # be patient, enjoy watching, switch to false for speed\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
